{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabnet.utils.logger import init_logger\n",
    "from tabnet.estimator import TabNetRegressor\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_dir = 'logs'\n",
    "logger_name = 'TestRegression'\n",
    "level = 'INFO'\n",
    "\n",
    "logger = init_logger(logger_dir=logger_dir, logger_name=logger_name, level=level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet = TabNetRegressor(\n",
    "    input_dims=13, output_dims=[1], logger=None, is_cuda=False,\n",
    "    reprs_dims=4, atten_dims=4, num_steps=3, num_indep=1, num_shared=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:49:48,513][WARNING][TabNet] Failed to load model from None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabNetRegressor(atten_dims=4, batch_size=1024, cate_dims=None,\n",
       "                cate_embed_dims=1, cate_indices=None, criterions=['mse'],\n",
       "                gamma=1.3, input_dims=13, is_cuda=False, is_shuffle=True,\n",
       "                logger=<RootLogger root (INFO)>, mask_type='sparsemax',\n",
       "                momentum=0.03, num_indep=1, num_shared=1, num_steps=3,\n",
       "                num_workers=4, output_dims=[1], pin_memory=True, reprs_dims=4,\n",
       "                task_weights=1, virtual_batch_size=128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabnet.build(path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "training_params = {\n",
    "    'batch_size': 256,\n",
    "    'max_epochs': 200,\n",
    "    'metrics': ['mse'],\n",
    "    'optimizer': Adam,\n",
    "    'optimizer_params': {'lr': 0.1},\n",
    "    'schedulers': [lr_scheduler.ExponentialLR],\n",
    "    'scheduler_params': {'gamma': 0.99}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:49:54,805][INFO][TabNet] start training.\n",
      "[2021-02-03 13:49:54,807][INFO][TabNet] ******************** epoch : 0 ********************\n",
      "[2021-02-03 13:49:58,629][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:49:58,636][INFO][TabNet] total_loss : 632.794189453125\n",
      "[2021-02-03 13:49:58,641][INFO][TabNet] task_loss : 632.7933349609375\n",
      "[2021-02-03 13:49:58,644][INFO][TabNet] mask_loss : -0.8424485325813293\n",
      "[2021-02-03 13:49:58,647][INFO][TabNet] time_cost : 0.12095332145690918\n",
      "[2021-02-03 13:49:58,650][INFO][TabNet] mean_squared_error : 23.378442764282227\n",
      "[2021-02-03 13:49:58,652][INFO][TabNet] ******************** epoch : 1 ********************\n",
      "[2021-02-03 13:50:02,344][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:02,347][INFO][TabNet] total_loss : 584.9020385742188\n",
      "[2021-02-03 13:50:02,349][INFO][TabNet] task_loss : 584.9011840820312\n",
      "[2021-02-03 13:50:02,351][INFO][TabNet] mask_loss : -0.8280443549156189\n",
      "[2021-02-03 13:50:02,353][INFO][TabNet] time_cost : 0.0260009765625\n",
      "[2021-02-03 13:50:02,354][INFO][TabNet] mean_squared_error : 22.565969467163086\n",
      "[2021-02-03 13:50:02,356][INFO][TabNet] ******************** epoch : 2 ********************\n",
      "[2021-02-03 13:50:05,987][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:05,990][INFO][TabNet] total_loss : 576.21728515625\n",
      "[2021-02-03 13:50:05,992][INFO][TabNet] task_loss : 576.216552734375\n",
      "[2021-02-03 13:50:05,994][INFO][TabNet] mask_loss : -0.7190998196601868\n",
      "[2021-02-03 13:50:05,995][INFO][TabNet] time_cost : 0.027994871139526367\n",
      "[2021-02-03 13:50:05,997][INFO][TabNet] mean_squared_error : 22.148229598999023\n",
      "[2021-02-03 13:50:05,999][INFO][TabNet] ******************** epoch : 3 ********************\n",
      "[2021-02-03 13:50:09,581][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:09,584][INFO][TabNet] total_loss : 541.3339233398438\n",
      "[2021-02-03 13:50:09,586][INFO][TabNet] task_loss : 541.333251953125\n",
      "[2021-02-03 13:50:09,588][INFO][TabNet] mask_loss : -0.6889278292655945\n",
      "[2021-02-03 13:50:09,590][INFO][TabNet] time_cost : 0.016993045806884766\n",
      "[2021-02-03 13:50:09,592][INFO][TabNet] mean_squared_error : 21.340463638305664\n",
      "[2021-02-03 13:50:09,593][INFO][TabNet] ******************** epoch : 4 ********************\n",
      "[2021-02-03 13:50:13,196][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:13,199][INFO][TabNet] total_loss : 514.3873901367188\n",
      "[2021-02-03 13:50:13,201][INFO][TabNet] task_loss : 514.38671875\n",
      "[2021-02-03 13:50:13,203][INFO][TabNet] mask_loss : -0.6651900410652161\n",
      "[2021-02-03 13:50:13,205][INFO][TabNet] time_cost : 0.021999597549438477\n",
      "[2021-02-03 13:50:13,206][INFO][TabNet] mean_squared_error : 20.851640701293945\n",
      "[2021-02-03 13:50:13,208][INFO][TabNet] ******************** epoch : 5 ********************\n",
      "[2021-02-03 13:50:16,799][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:16,801][INFO][TabNet] total_loss : 501.3515930175781\n",
      "[2021-02-03 13:50:16,803][INFO][TabNet] task_loss : 501.3509521484375\n",
      "[2021-02-03 13:50:16,805][INFO][TabNet] mask_loss : -0.6331729292869568\n",
      "[2021-02-03 13:50:16,807][INFO][TabNet] time_cost : 0.023000240325927734\n",
      "[2021-02-03 13:50:16,808][INFO][TabNet] mean_squared_error : 20.669137954711914\n",
      "[2021-02-03 13:50:16,810][INFO][TabNet] ******************** epoch : 6 ********************\n",
      "[2021-02-03 13:50:20,404][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:20,406][INFO][TabNet] total_loss : 486.9520263671875\n",
      "[2021-02-03 13:50:20,408][INFO][TabNet] task_loss : 486.95147705078125\n",
      "[2021-02-03 13:50:20,410][INFO][TabNet] mask_loss : -0.5448563694953918\n",
      "[2021-02-03 13:50:20,412][INFO][TabNet] time_cost : 0.026999473571777344\n",
      "[2021-02-03 13:50:20,415][INFO][TabNet] mean_squared_error : 20.153953552246094\n",
      "[2021-02-03 13:50:20,416][INFO][TabNet] ******************** epoch : 7 ********************\n",
      "[2021-02-03 13:50:24,000][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:24,003][INFO][TabNet] total_loss : 434.5855407714844\n",
      "[2021-02-03 13:50:24,005][INFO][TabNet] task_loss : 434.58502197265625\n",
      "[2021-02-03 13:50:24,007][INFO][TabNet] mask_loss : -0.5054203867912292\n",
      "[2021-02-03 13:50:24,009][INFO][TabNet] time_cost : 0.023000240325927734\n",
      "[2021-02-03 13:50:24,011][INFO][TabNet] mean_squared_error : 18.939056396484375\n",
      "[2021-02-03 13:50:24,014][INFO][TabNet] ******************** epoch : 8 ********************\n",
      "[2021-02-03 13:50:27,608][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:27,610][INFO][TabNet] total_loss : 406.17486572265625\n",
      "[2021-02-03 13:50:27,613][INFO][TabNet] task_loss : 406.1744384765625\n",
      "[2021-02-03 13:50:27,614][INFO][TabNet] mask_loss : -0.4414335787296295\n",
      "[2021-02-03 13:50:27,616][INFO][TabNet] time_cost : 0.023981094360351562\n",
      "[2021-02-03 13:50:27,618][INFO][TabNet] mean_squared_error : 18.235618591308594\n",
      "[2021-02-03 13:50:27,619][INFO][TabNet] ******************** epoch : 9 ********************\n",
      "[2021-02-03 13:50:31,182][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:31,185][INFO][TabNet] total_loss : 367.90386962890625\n",
      "[2021-02-03 13:50:31,188][INFO][TabNet] task_loss : 367.9034729003906\n",
      "[2021-02-03 13:50:31,189][INFO][TabNet] mask_loss : -0.3949859142303467\n",
      "[2021-02-03 13:50:31,191][INFO][TabNet] time_cost : 0.020987987518310547\n",
      "[2021-02-03 13:50:31,193][INFO][TabNet] mean_squared_error : 17.468257904052734\n",
      "[2021-02-03 13:50:31,195][INFO][TabNet] ******************** epoch : 10 ********************\n",
      "[2021-02-03 13:50:34,792][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:34,796][INFO][TabNet] total_loss : 293.0876770019531\n",
      "[2021-02-03 13:50:34,798][INFO][TabNet] task_loss : 293.08734130859375\n",
      "[2021-02-03 13:50:34,800][INFO][TabNet] mask_loss : -0.3350120782852173\n",
      "[2021-02-03 13:50:34,802][INFO][TabNet] time_cost : 0.02299809455871582\n",
      "[2021-02-03 13:50:34,805][INFO][TabNet] mean_squared_error : 15.43685245513916\n",
      "[2021-02-03 13:50:34,807][INFO][TabNet] ******************** epoch : 11 ********************\n",
      "[2021-02-03 13:50:38,394][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:38,396][INFO][TabNet] total_loss : 294.2857666015625\n",
      "[2021-02-03 13:50:38,398][INFO][TabNet] task_loss : 294.2854919433594\n",
      "[2021-02-03 13:50:38,400][INFO][TabNet] mask_loss : -0.27661368250846863\n",
      "[2021-02-03 13:50:38,402][INFO][TabNet] time_cost : 0.028003931045532227\n",
      "[2021-02-03 13:50:38,404][INFO][TabNet] mean_squared_error : 14.940980911254883\n",
      "[2021-02-03 13:50:38,405][INFO][TabNet] ******************** epoch : 12 ********************\n",
      "[2021-02-03 13:50:42,011][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:42,012][INFO][TabNet] total_loss : 227.90853881835938\n",
      "[2021-02-03 13:50:42,014][INFO][TabNet] task_loss : 227.9082794189453\n",
      "[2021-02-03 13:50:42,016][INFO][TabNet] mask_loss : -0.2643672227859497\n",
      "[2021-02-03 13:50:42,017][INFO][TabNet] time_cost : 0.02700352668762207\n",
      "[2021-02-03 13:50:42,019][INFO][TabNet] mean_squared_error : 12.784127235412598\n",
      "[2021-02-03 13:50:42,021][INFO][TabNet] ******************** epoch : 13 ********************\n",
      "[2021-02-03 13:50:45,607][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:45,608][INFO][TabNet] total_loss : 213.13523864746094\n",
      "[2021-02-03 13:50:45,610][INFO][TabNet] task_loss : 213.13499450683594\n",
      "[2021-02-03 13:50:45,612][INFO][TabNet] mask_loss : -0.24836039543151855\n",
      "[2021-02-03 13:50:45,613][INFO][TabNet] time_cost : 0.0220029354095459\n",
      "[2021-02-03 13:50:45,615][INFO][TabNet] mean_squared_error : 11.867348670959473\n",
      "[2021-02-03 13:50:45,616][INFO][TabNet] ******************** epoch : 14 ********************\n",
      "[2021-02-03 13:50:49,205][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:49,209][INFO][TabNet] total_loss : 205.1017608642578\n",
      "[2021-02-03 13:50:49,211][INFO][TabNet] task_loss : 205.10153198242188\n",
      "[2021-02-03 13:50:49,213][INFO][TabNet] mask_loss : -0.2313467413187027\n",
      "[2021-02-03 13:50:49,215][INFO][TabNet] time_cost : 0.027972698211669922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:50:49,216][INFO][TabNet] mean_squared_error : 11.399986267089844\n",
      "[2021-02-03 13:50:49,218][INFO][TabNet] ******************** epoch : 15 ********************\n",
      "[2021-02-03 13:50:53,088][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:53,091][INFO][TabNet] total_loss : 163.3161163330078\n",
      "[2021-02-03 13:50:53,093][INFO][TabNet] task_loss : 163.31588745117188\n",
      "[2021-02-03 13:50:53,094][INFO][TabNet] mask_loss : -0.23289121687412262\n",
      "[2021-02-03 13:50:53,096][INFO][TabNet] time_cost : 0.029971837997436523\n",
      "[2021-02-03 13:50:53,097][INFO][TabNet] mean_squared_error : 9.76811408996582\n",
      "[2021-02-03 13:50:53,098][INFO][TabNet] ******************** epoch : 16 ********************\n",
      "[2021-02-03 13:50:57,023][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:50:57,025][INFO][TabNet] total_loss : 153.5235595703125\n",
      "[2021-02-03 13:50:57,027][INFO][TabNet] task_loss : 153.5233154296875\n",
      "[2021-02-03 13:50:57,029][INFO][TabNet] mask_loss : -0.24615858495235443\n",
      "[2021-02-03 13:50:57,030][INFO][TabNet] time_cost : 0.026994705200195312\n",
      "[2021-02-03 13:50:57,032][INFO][TabNet] mean_squared_error : 9.093061447143555\n",
      "[2021-02-03 13:50:57,034][INFO][TabNet] ******************** epoch : 17 ********************\n",
      "[2021-02-03 13:51:00,785][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:00,788][INFO][TabNet] total_loss : 125.67643737792969\n",
      "[2021-02-03 13:51:00,790][INFO][TabNet] task_loss : 125.67621612548828\n",
      "[2021-02-03 13:51:00,793][INFO][TabNet] mask_loss : -0.22352750599384308\n",
      "[2021-02-03 13:51:00,795][INFO][TabNet] time_cost : 0.01599264144897461\n",
      "[2021-02-03 13:51:00,797][INFO][TabNet] mean_squared_error : 8.031285285949707\n",
      "[2021-02-03 13:51:00,799][INFO][TabNet] ******************** epoch : 18 ********************\n",
      "[2021-02-03 13:51:04,425][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:04,428][INFO][TabNet] total_loss : 113.61591339111328\n",
      "[2021-02-03 13:51:04,430][INFO][TabNet] task_loss : 113.61569213867188\n",
      "[2021-02-03 13:51:04,431][INFO][TabNet] mask_loss : -0.22428900003433228\n",
      "[2021-02-03 13:51:04,433][INFO][TabNet] time_cost : 0.017000675201416016\n",
      "[2021-02-03 13:51:04,435][INFO][TabNet] mean_squared_error : 7.6648125648498535\n",
      "[2021-02-03 13:51:04,437][INFO][TabNet] ******************** epoch : 19 ********************\n",
      "[2021-02-03 13:51:08,039][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:08,041][INFO][TabNet] total_loss : 98.22683715820312\n",
      "[2021-02-03 13:51:08,043][INFO][TabNet] task_loss : 98.22662353515625\n",
      "[2021-02-03 13:51:08,045][INFO][TabNet] mask_loss : -0.21187172830104828\n",
      "[2021-02-03 13:51:08,046][INFO][TabNet] time_cost : 0.02300095558166504\n",
      "[2021-02-03 13:51:08,048][INFO][TabNet] mean_squared_error : 7.3516011238098145\n",
      "[2021-02-03 13:51:08,049][INFO][TabNet] ******************** epoch : 20 ********************\n",
      "[2021-02-03 13:51:11,667][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:11,670][INFO][TabNet] total_loss : 99.5584945678711\n",
      "[2021-02-03 13:51:11,672][INFO][TabNet] task_loss : 99.5582504272461\n",
      "[2021-02-03 13:51:11,675][INFO][TabNet] mask_loss : -0.24779726564884186\n",
      "[2021-02-03 13:51:11,677][INFO][TabNet] time_cost : 0.02600240707397461\n",
      "[2021-02-03 13:51:11,679][INFO][TabNet] mean_squared_error : 6.968041896820068\n",
      "[2021-02-03 13:51:11,681][INFO][TabNet] ******************** epoch : 21 ********************\n",
      "[2021-02-03 13:51:15,455][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:15,457][INFO][TabNet] total_loss : 116.47251892089844\n",
      "[2021-02-03 13:51:15,459][INFO][TabNet] task_loss : 116.47225952148438\n",
      "[2021-02-03 13:51:15,461][INFO][TabNet] mask_loss : -0.25569072365760803\n",
      "[2021-02-03 13:51:15,463][INFO][TabNet] time_cost : 0.022000551223754883\n",
      "[2021-02-03 13:51:15,464][INFO][TabNet] mean_squared_error : 7.583227157592773\n",
      "[2021-02-03 13:51:15,465][INFO][TabNet] ******************** epoch : 22 ********************\n",
      "[2021-02-03 13:51:19,168][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:19,169][INFO][TabNet] total_loss : 94.24093627929688\n",
      "[2021-02-03 13:51:19,171][INFO][TabNet] task_loss : 94.24065399169922\n",
      "[2021-02-03 13:51:19,172][INFO][TabNet] mask_loss : -0.284455806016922\n",
      "[2021-02-03 13:51:19,173][INFO][TabNet] time_cost : 0.023004531860351562\n",
      "[2021-02-03 13:51:19,175][INFO][TabNet] mean_squared_error : 6.685399055480957\n",
      "[2021-02-03 13:51:19,176][INFO][TabNet] ******************** epoch : 23 ********************\n",
      "[2021-02-03 13:51:22,807][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:22,810][INFO][TabNet] total_loss : 81.7034683227539\n",
      "[2021-02-03 13:51:22,812][INFO][TabNet] task_loss : 81.70319366455078\n",
      "[2021-02-03 13:51:22,813][INFO][TabNet] mask_loss : -0.2772270143032074\n",
      "[2021-02-03 13:51:22,815][INFO][TabNet] time_cost : 0.016001462936401367\n",
      "[2021-02-03 13:51:22,817][INFO][TabNet] mean_squared_error : 6.498589038848877\n",
      "[2021-02-03 13:51:22,818][INFO][TabNet] ******************** epoch : 24 ********************\n",
      "[2021-02-03 13:51:26,621][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:26,623][INFO][TabNet] total_loss : 61.9666748046875\n",
      "[2021-02-03 13:51:26,624][INFO][TabNet] task_loss : 61.96643829345703\n",
      "[2021-02-03 13:51:26,626][INFO][TabNet] mask_loss : -0.238095223903656\n",
      "[2021-02-03 13:51:26,627][INFO][TabNet] time_cost : 0.02500009536743164\n",
      "[2021-02-03 13:51:26,629][INFO][TabNet] mean_squared_error : 5.7045440673828125\n",
      "[2021-02-03 13:51:26,630][INFO][TabNet] ******************** epoch : 25 ********************\n",
      "[2021-02-03 13:51:30,418][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:30,420][INFO][TabNet] total_loss : 68.55381774902344\n",
      "[2021-02-03 13:51:30,422][INFO][TabNet] task_loss : 68.55360412597656\n",
      "[2021-02-03 13:51:30,424][INFO][TabNet] mask_loss : -0.2173832207918167\n",
      "[2021-02-03 13:51:30,426][INFO][TabNet] time_cost : 0.01800084114074707\n",
      "[2021-02-03 13:51:30,428][INFO][TabNet] mean_squared_error : 6.1129045486450195\n",
      "[2021-02-03 13:51:30,430][INFO][TabNet] ******************** epoch : 26 ********************\n",
      "[2021-02-03 13:51:34,059][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:34,061][INFO][TabNet] total_loss : 44.88084411621094\n",
      "[2021-02-03 13:51:34,063][INFO][TabNet] task_loss : 44.880653381347656\n",
      "[2021-02-03 13:51:34,065][INFO][TabNet] mask_loss : -0.19059239327907562\n",
      "[2021-02-03 13:51:34,068][INFO][TabNet] time_cost : 0.02799701690673828\n",
      "[2021-02-03 13:51:34,070][INFO][TabNet] mean_squared_error : 5.175684452056885\n",
      "[2021-02-03 13:51:34,071][INFO][TabNet] ******************** epoch : 27 ********************\n",
      "[2021-02-03 13:51:37,686][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:37,688][INFO][TabNet] total_loss : 57.532936096191406\n",
      "[2021-02-03 13:51:37,690][INFO][TabNet] task_loss : 57.532718658447266\n",
      "[2021-02-03 13:51:37,692][INFO][TabNet] mask_loss : -0.21850483119487762\n",
      "[2021-02-03 13:51:37,693][INFO][TabNet] time_cost : 0.020000457763671875\n",
      "[2021-02-03 13:51:37,695][INFO][TabNet] mean_squared_error : 5.675477504730225\n",
      "[2021-02-03 13:51:37,697][INFO][TabNet] ******************** epoch : 28 ********************\n",
      "[2021-02-03 13:51:41,558][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:41,560][INFO][TabNet] total_loss : 44.65328598022461\n",
      "[2021-02-03 13:51:41,561][INFO][TabNet] task_loss : 44.65306854248047\n",
      "[2021-02-03 13:51:41,563][INFO][TabNet] mask_loss : -0.21574340760707855\n",
      "[2021-02-03 13:51:41,564][INFO][TabNet] time_cost : 0.025997161865234375\n",
      "[2021-02-03 13:51:41,566][INFO][TabNet] mean_squared_error : 5.166195869445801\n",
      "[2021-02-03 13:51:41,568][INFO][TabNet] ******************** epoch : 29 ********************\n",
      "[2021-02-03 13:51:45,365][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:45,367][INFO][TabNet] total_loss : 52.695106506347656\n",
      "[2021-02-03 13:51:45,369][INFO][TabNet] task_loss : 52.69489669799805\n",
      "[2021-02-03 13:51:45,371][INFO][TabNet] mask_loss : -0.21057158708572388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:51:45,372][INFO][TabNet] time_cost : 0.022998332977294922\n",
      "[2021-02-03 13:51:45,373][INFO][TabNet] mean_squared_error : 5.6942458152771\n",
      "[2021-02-03 13:51:45,375][INFO][TabNet] ******************** epoch : 30 ********************\n",
      "[2021-02-03 13:51:49,164][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:49,167][INFO][TabNet] total_loss : 56.99422073364258\n",
      "[2021-02-03 13:51:49,169][INFO][TabNet] task_loss : 56.99397659301758\n",
      "[2021-02-03 13:51:49,171][INFO][TabNet] mask_loss : -0.24253641068935394\n",
      "[2021-02-03 13:51:49,173][INFO][TabNet] time_cost : 0.018001556396484375\n",
      "[2021-02-03 13:51:49,175][INFO][TabNet] mean_squared_error : 5.944016456604004\n",
      "[2021-02-03 13:51:49,176][INFO][TabNet] ******************** epoch : 31 ********************\n",
      "[2021-02-03 13:51:52,834][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:52,835][INFO][TabNet] total_loss : 76.60246276855469\n",
      "[2021-02-03 13:51:52,836][INFO][TabNet] task_loss : 76.60221099853516\n",
      "[2021-02-03 13:51:52,838][INFO][TabNet] mask_loss : -0.24936330318450928\n",
      "[2021-02-03 13:51:52,839][INFO][TabNet] time_cost : 0.021993637084960938\n",
      "[2021-02-03 13:51:52,840][INFO][TabNet] mean_squared_error : 6.847140312194824\n",
      "[2021-02-03 13:51:52,842][INFO][TabNet] ******************** epoch : 32 ********************\n",
      "[2021-02-03 13:51:56,529][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:51:56,531][INFO][TabNet] total_loss : 65.14525604248047\n",
      "[2021-02-03 13:51:56,533][INFO][TabNet] task_loss : 65.14502716064453\n",
      "[2021-02-03 13:51:56,535][INFO][TabNet] mask_loss : -0.2320277839899063\n",
      "[2021-02-03 13:51:56,536][INFO][TabNet] time_cost : 0.02099299430847168\n",
      "[2021-02-03 13:51:56,537][INFO][TabNet] mean_squared_error : 6.151433944702148\n",
      "[2021-02-03 13:51:56,538][INFO][TabNet] ******************** epoch : 33 ********************\n",
      "[2021-02-03 13:52:00,469][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:00,471][INFO][TabNet] total_loss : 48.32080841064453\n",
      "[2021-02-03 13:52:00,474][INFO][TabNet] task_loss : 48.32058334350586\n",
      "[2021-02-03 13:52:00,477][INFO][TabNet] mask_loss : -0.22477658092975616\n",
      "[2021-02-03 13:52:00,479][INFO][TabNet] time_cost : 0.02199554443359375\n",
      "[2021-02-03 13:52:00,481][INFO][TabNet] mean_squared_error : 5.1956610679626465\n",
      "[2021-02-03 13:52:00,483][INFO][TabNet] ******************** epoch : 34 ********************\n",
      "[2021-02-03 13:52:04,171][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:04,174][INFO][TabNet] total_loss : 35.46535873413086\n",
      "[2021-02-03 13:52:04,176][INFO][TabNet] task_loss : 35.465126037597656\n",
      "[2021-02-03 13:52:04,178][INFO][TabNet] mask_loss : -0.23264680802822113\n",
      "[2021-02-03 13:52:04,181][INFO][TabNet] time_cost : 0.021001577377319336\n",
      "[2021-02-03 13:52:04,183][INFO][TabNet] mean_squared_error : 4.633011817932129\n",
      "[2021-02-03 13:52:04,184][INFO][TabNet] ******************** epoch : 35 ********************\n",
      "[2021-02-03 13:52:07,839][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:07,842][INFO][TabNet] total_loss : 28.61254119873047\n",
      "[2021-02-03 13:52:07,844][INFO][TabNet] task_loss : 28.61229705810547\n",
      "[2021-02-03 13:52:07,845][INFO][TabNet] mask_loss : -0.2435142546892166\n",
      "[2021-02-03 13:52:07,847][INFO][TabNet] time_cost : 0.01999950408935547\n",
      "[2021-02-03 13:52:07,848][INFO][TabNet] mean_squared_error : 4.129035472869873\n",
      "[2021-02-03 13:52:07,850][INFO][TabNet] ******************** epoch : 36 ********************\n",
      "[2021-02-03 13:52:12,576][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:12,578][INFO][TabNet] total_loss : 33.667083740234375\n",
      "[2021-02-03 13:52:12,580][INFO][TabNet] task_loss : 33.666812896728516\n",
      "[2021-02-03 13:52:12,581][INFO][TabNet] mask_loss : -0.27166998386383057\n",
      "[2021-02-03 13:52:12,583][INFO][TabNet] time_cost : 0.023966550827026367\n",
      "[2021-02-03 13:52:12,584][INFO][TabNet] mean_squared_error : 4.419261932373047\n",
      "[2021-02-03 13:52:12,586][INFO][TabNet] ******************** epoch : 37 ********************\n",
      "[2021-02-03 13:52:16,332][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:16,333][INFO][TabNet] total_loss : 35.97385787963867\n",
      "[2021-02-03 13:52:16,335][INFO][TabNet] task_loss : 35.97359085083008\n",
      "[2021-02-03 13:52:16,337][INFO][TabNet] mask_loss : -0.26838648319244385\n",
      "[2021-02-03 13:52:16,338][INFO][TabNet] time_cost : 0.029984712600708008\n",
      "[2021-02-03 13:52:16,339][INFO][TabNet] mean_squared_error : 4.606082439422607\n",
      "[2021-02-03 13:52:16,341][INFO][TabNet] ******************** epoch : 38 ********************\n",
      "[2021-02-03 13:52:19,960][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:19,963][INFO][TabNet] total_loss : 29.280366897583008\n",
      "[2021-02-03 13:52:19,965][INFO][TabNet] task_loss : 29.280101776123047\n",
      "[2021-02-03 13:52:19,967][INFO][TabNet] mask_loss : -0.26487573981285095\n",
      "[2021-02-03 13:52:19,969][INFO][TabNet] time_cost : 0.020002126693725586\n",
      "[2021-02-03 13:52:19,971][INFO][TabNet] mean_squared_error : 4.103748798370361\n",
      "[2021-02-03 13:52:19,972][INFO][TabNet] ******************** epoch : 39 ********************\n",
      "[2021-02-03 13:52:23,652][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:23,655][INFO][TabNet] total_loss : 31.3753604888916\n",
      "[2021-02-03 13:52:23,657][INFO][TabNet] task_loss : 31.375076293945312\n",
      "[2021-02-03 13:52:23,659][INFO][TabNet] mask_loss : -0.28403592109680176\n",
      "[2021-02-03 13:52:23,661][INFO][TabNet] time_cost : 0.026999473571777344\n",
      "[2021-02-03 13:52:23,662][INFO][TabNet] mean_squared_error : 4.266007900238037\n",
      "[2021-02-03 13:52:23,664][INFO][TabNet] ******************** epoch : 40 ********************\n",
      "[2021-02-03 13:52:27,265][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:27,268][INFO][TabNet] total_loss : 28.79096221923828\n",
      "[2021-02-03 13:52:27,270][INFO][TabNet] task_loss : 28.790714263916016\n",
      "[2021-02-03 13:52:27,272][INFO][TabNet] mask_loss : -0.24819530546665192\n",
      "[2021-02-03 13:52:27,273][INFO][TabNet] time_cost : 0.02099895477294922\n",
      "[2021-02-03 13:52:27,275][INFO][TabNet] mean_squared_error : 3.8812637329101562\n",
      "[2021-02-03 13:52:27,277][INFO][TabNet] ******************** epoch : 41 ********************\n",
      "[2021-02-03 13:52:30,892][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:30,895][INFO][TabNet] total_loss : 32.48232650756836\n",
      "[2021-02-03 13:52:30,897][INFO][TabNet] task_loss : 32.482086181640625\n",
      "[2021-02-03 13:52:30,899][INFO][TabNet] mask_loss : -0.2389087826013565\n",
      "[2021-02-03 13:52:30,900][INFO][TabNet] time_cost : 0.023000717163085938\n",
      "[2021-02-03 13:52:30,902][INFO][TabNet] mean_squared_error : 4.042893409729004\n",
      "[2021-02-03 13:52:30,903][INFO][TabNet] ******************** epoch : 42 ********************\n",
      "[2021-02-03 13:52:34,945][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:34,947][INFO][TabNet] total_loss : 23.008689880371094\n",
      "[2021-02-03 13:52:34,949][INFO][TabNet] task_loss : 23.008440017700195\n",
      "[2021-02-03 13:52:34,950][INFO][TabNet] mask_loss : -0.25055697560310364\n",
      "[2021-02-03 13:52:34,952][INFO][TabNet] time_cost : 0.029004812240600586\n",
      "[2021-02-03 13:52:34,953][INFO][TabNet] mean_squared_error : 3.636322498321533\n",
      "[2021-02-03 13:52:34,955][INFO][TabNet] ******************** epoch : 43 ********************\n",
      "[2021-02-03 13:52:38,933][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:38,936][INFO][TabNet] total_loss : 26.338871002197266\n",
      "[2021-02-03 13:52:38,937][INFO][TabNet] task_loss : 26.338619232177734\n",
      "[2021-02-03 13:52:38,939][INFO][TabNet] mask_loss : -0.25124120712280273\n",
      "[2021-02-03 13:52:38,940][INFO][TabNet] time_cost : 0.028980731964111328\n",
      "[2021-02-03 13:52:38,942][INFO][TabNet] mean_squared_error : 3.827805757522583\n",
      "[2021-02-03 13:52:38,944][INFO][TabNet] ******************** epoch : 44 ********************\n",
      "[2021-02-03 13:52:43,209][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:43,211][INFO][TabNet] total_loss : 31.994483947753906\n",
      "[2021-02-03 13:52:43,213][INFO][TabNet] task_loss : 31.994239807128906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:52:43,215][INFO][TabNet] mask_loss : -0.24501705169677734\n",
      "[2021-02-03 13:52:43,217][INFO][TabNet] time_cost : 0.02295231819152832\n",
      "[2021-02-03 13:52:43,219][INFO][TabNet] mean_squared_error : 4.117396831512451\n",
      "[2021-02-03 13:52:43,220][INFO][TabNet] ******************** epoch : 45 ********************\n",
      "[2021-02-03 13:52:48,100][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:48,102][INFO][TabNet] total_loss : 31.375768661499023\n",
      "[2021-02-03 13:52:48,104][INFO][TabNet] task_loss : 31.375524520874023\n",
      "[2021-02-03 13:52:48,107][INFO][TabNet] mask_loss : -0.2441369742155075\n",
      "[2021-02-03 13:52:48,109][INFO][TabNet] time_cost : 0.019999980926513672\n",
      "[2021-02-03 13:52:48,113][INFO][TabNet] mean_squared_error : 4.04672384262085\n",
      "[2021-02-03 13:52:48,118][INFO][TabNet] ******************** epoch : 46 ********************\n",
      "[2021-02-03 13:52:54,454][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:54,456][INFO][TabNet] total_loss : 23.792570114135742\n",
      "[2021-02-03 13:52:54,458][INFO][TabNet] task_loss : 23.792322158813477\n",
      "[2021-02-03 13:52:54,460][INFO][TabNet] mask_loss : -0.24768459796905518\n",
      "[2021-02-03 13:52:54,462][INFO][TabNet] time_cost : 0.030002355575561523\n",
      "[2021-02-03 13:52:54,463][INFO][TabNet] mean_squared_error : 3.6722469329833984\n",
      "[2021-02-03 13:52:54,465][INFO][TabNet] ******************** epoch : 47 ********************\n",
      "[2021-02-03 13:52:59,035][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:52:59,039][INFO][TabNet] total_loss : 25.312496185302734\n",
      "[2021-02-03 13:52:59,042][INFO][TabNet] task_loss : 25.312257766723633\n",
      "[2021-02-03 13:52:59,045][INFO][TabNet] mask_loss : -0.23829962313175201\n",
      "[2021-02-03 13:52:59,047][INFO][TabNet] time_cost : 0.023993253707885742\n",
      "[2021-02-03 13:52:59,049][INFO][TabNet] mean_squared_error : 3.6714797019958496\n",
      "[2021-02-03 13:52:59,051][INFO][TabNet] ******************** epoch : 48 ********************\n",
      "[2021-02-03 13:53:03,566][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:03,569][INFO][TabNet] total_loss : 21.444931030273438\n",
      "[2021-02-03 13:53:03,571][INFO][TabNet] task_loss : 21.444677352905273\n",
      "[2021-02-03 13:53:03,573][INFO][TabNet] mask_loss : -0.2534135580062866\n",
      "[2021-02-03 13:53:03,577][INFO][TabNet] time_cost : 0.03300333023071289\n",
      "[2021-02-03 13:53:03,579][INFO][TabNet] mean_squared_error : 3.4644346237182617\n",
      "[2021-02-03 13:53:03,581][INFO][TabNet] ******************** epoch : 49 ********************\n",
      "[2021-02-03 13:53:08,298][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:08,300][INFO][TabNet] total_loss : 25.82547378540039\n",
      "[2021-02-03 13:53:08,302][INFO][TabNet] task_loss : 25.82523536682129\n",
      "[2021-02-03 13:53:08,303][INFO][TabNet] mask_loss : -0.23903493583202362\n",
      "[2021-02-03 13:53:08,305][INFO][TabNet] time_cost : 0.02399897575378418\n",
      "[2021-02-03 13:53:08,306][INFO][TabNet] mean_squared_error : 3.7340683937072754\n",
      "[2021-02-03 13:53:08,308][INFO][TabNet] ******************** epoch : 50 ********************\n",
      "[2021-02-03 13:53:12,726][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:12,729][INFO][TabNet] total_loss : 21.856769561767578\n",
      "[2021-02-03 13:53:12,731][INFO][TabNet] task_loss : 21.85652732849121\n",
      "[2021-02-03 13:53:12,733][INFO][TabNet] mask_loss : -0.2415623813867569\n",
      "[2021-02-03 13:53:12,736][INFO][TabNet] time_cost : 0.029000520706176758\n",
      "[2021-02-03 13:53:12,738][INFO][TabNet] mean_squared_error : 3.6094653606414795\n",
      "[2021-02-03 13:53:12,740][INFO][TabNet] ******************** epoch : 51 ********************\n",
      "[2021-02-03 13:53:16,424][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:16,426][INFO][TabNet] total_loss : 22.715354919433594\n",
      "[2021-02-03 13:53:16,428][INFO][TabNet] task_loss : 22.715118408203125\n",
      "[2021-02-03 13:53:16,430][INFO][TabNet] mask_loss : -0.23689983785152435\n",
      "[2021-02-03 13:53:16,431][INFO][TabNet] time_cost : 0.020000457763671875\n",
      "[2021-02-03 13:53:16,433][INFO][TabNet] mean_squared_error : 3.7558445930480957\n",
      "[2021-02-03 13:53:16,434][INFO][TabNet] ******************** epoch : 52 ********************\n",
      "[2021-02-03 13:53:20,067][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:20,071][INFO][TabNet] total_loss : 23.610177993774414\n",
      "[2021-02-03 13:53:20,073][INFO][TabNet] task_loss : 23.60993003845215\n",
      "[2021-02-03 13:53:20,076][INFO][TabNet] mask_loss : -0.24737979471683502\n",
      "[2021-02-03 13:53:20,078][INFO][TabNet] time_cost : 0.01600027084350586\n",
      "[2021-02-03 13:53:20,080][INFO][TabNet] mean_squared_error : 3.5169689655303955\n",
      "[2021-02-03 13:53:20,082][INFO][TabNet] ******************** epoch : 53 ********************\n",
      "[2021-02-03 13:53:23,783][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:23,786][INFO][TabNet] total_loss : 24.170040130615234\n",
      "[2021-02-03 13:53:23,789][INFO][TabNet] task_loss : 24.169788360595703\n",
      "[2021-02-03 13:53:23,791][INFO][TabNet] mask_loss : -0.2515017092227936\n",
      "[2021-02-03 13:53:23,793][INFO][TabNet] time_cost : 0.02500176429748535\n",
      "[2021-02-03 13:53:23,796][INFO][TabNet] mean_squared_error : 3.837327718734741\n",
      "[2021-02-03 13:53:23,798][INFO][TabNet] ******************** epoch : 54 ********************\n",
      "[2021-02-03 13:53:27,571][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:27,573][INFO][TabNet] total_loss : 24.230867385864258\n",
      "[2021-02-03 13:53:27,576][INFO][TabNet] task_loss : 24.23064422607422\n",
      "[2021-02-03 13:53:27,578][INFO][TabNet] mask_loss : -0.22336037456989288\n",
      "[2021-02-03 13:53:27,579][INFO][TabNet] time_cost : 0.021999835968017578\n",
      "[2021-02-03 13:53:27,580][INFO][TabNet] mean_squared_error : 3.641923666000366\n",
      "[2021-02-03 13:53:27,582][INFO][TabNet] ******************** epoch : 55 ********************\n",
      "[2021-02-03 13:53:31,372][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:31,376][INFO][TabNet] total_loss : 24.756305694580078\n",
      "[2021-02-03 13:53:31,379][INFO][TabNet] task_loss : 24.756088256835938\n",
      "[2021-02-03 13:53:31,381][INFO][TabNet] mask_loss : -0.21663518249988556\n",
      "[2021-02-03 13:53:31,383][INFO][TabNet] time_cost : 0.027962207794189453\n",
      "[2021-02-03 13:53:31,385][INFO][TabNet] mean_squared_error : 3.62992000579834\n",
      "[2021-02-03 13:53:31,387][INFO][TabNet] ******************** epoch : 56 ********************\n",
      "[2021-02-03 13:53:35,143][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:35,146][INFO][TabNet] total_loss : 26.031719207763672\n",
      "[2021-02-03 13:53:35,148][INFO][TabNet] task_loss : 26.0314998626709\n",
      "[2021-02-03 13:53:35,151][INFO][TabNet] mask_loss : -0.2202713042497635\n",
      "[2021-02-03 13:53:35,153][INFO][TabNet] time_cost : 0.018999338150024414\n",
      "[2021-02-03 13:53:35,154][INFO][TabNet] mean_squared_error : 3.6762518882751465\n",
      "[2021-02-03 13:53:35,155][INFO][TabNet] ******************** epoch : 57 ********************\n",
      "[2021-02-03 13:53:38,848][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:38,852][INFO][TabNet] total_loss : 18.596790313720703\n",
      "[2021-02-03 13:53:38,854][INFO][TabNet] task_loss : 18.596567153930664\n",
      "[2021-02-03 13:53:38,856][INFO][TabNet] mask_loss : -0.22340011596679688\n",
      "[2021-02-03 13:53:38,858][INFO][TabNet] time_cost : 0.019997835159301758\n",
      "[2021-02-03 13:53:38,859][INFO][TabNet] mean_squared_error : 3.2632346153259277\n",
      "[2021-02-03 13:53:38,861][INFO][TabNet] ******************** epoch : 58 ********************\n",
      "[2021-02-03 13:53:42,550][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:42,553][INFO][TabNet] total_loss : 24.68695068359375\n",
      "[2021-02-03 13:53:42,555][INFO][TabNet] task_loss : 24.68673324584961\n",
      "[2021-02-03 13:53:42,558][INFO][TabNet] mask_loss : -0.21771667897701263\n",
      "[2021-02-03 13:53:42,560][INFO][TabNet] time_cost : 0.02099299430847168\n",
      "[2021-02-03 13:53:42,562][INFO][TabNet] mean_squared_error : 3.6788721084594727\n",
      "[2021-02-03 13:53:42,564][INFO][TabNet] ******************** epoch : 59 ********************\n",
      "[2021-02-03 13:53:46,274][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:46,275][INFO][TabNet] total_loss : 21.520490646362305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:53:46,277][INFO][TabNet] task_loss : 21.520273208618164\n",
      "[2021-02-03 13:53:46,278][INFO][TabNet] mask_loss : -0.21806275844573975\n",
      "[2021-02-03 13:53:46,280][INFO][TabNet] time_cost : 0.02799534797668457\n",
      "[2021-02-03 13:53:46,281][INFO][TabNet] mean_squared_error : 3.3651249408721924\n",
      "[2021-02-03 13:53:46,282][INFO][TabNet] ******************** epoch : 60 ********************\n",
      "[2021-02-03 13:53:50,021][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:50,023][INFO][TabNet] total_loss : 23.88224220275879\n",
      "[2021-02-03 13:53:50,026][INFO][TabNet] task_loss : 23.882028579711914\n",
      "[2021-02-03 13:53:50,027][INFO][TabNet] mask_loss : -0.21427935361862183\n",
      "[2021-02-03 13:53:50,029][INFO][TabNet] time_cost : 0.026004791259765625\n",
      "[2021-02-03 13:53:50,031][INFO][TabNet] mean_squared_error : 3.6638693809509277\n",
      "[2021-02-03 13:53:50,032][INFO][TabNet] ******************** epoch : 61 ********************\n",
      "[2021-02-03 13:53:53,793][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:53,795][INFO][TabNet] total_loss : 23.889217376708984\n",
      "[2021-02-03 13:53:53,798][INFO][TabNet] task_loss : 23.88899803161621\n",
      "[2021-02-03 13:53:53,800][INFO][TabNet] mask_loss : -0.21992921829223633\n",
      "[2021-02-03 13:53:53,802][INFO][TabNet] time_cost : 0.019997835159301758\n",
      "[2021-02-03 13:53:53,804][INFO][TabNet] mean_squared_error : 3.555537223815918\n",
      "[2021-02-03 13:53:53,806][INFO][TabNet] ******************** epoch : 62 ********************\n",
      "[2021-02-03 13:53:57,532][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:53:57,535][INFO][TabNet] total_loss : 19.653789520263672\n",
      "[2021-02-03 13:53:57,537][INFO][TabNet] task_loss : 19.653566360473633\n",
      "[2021-02-03 13:53:57,538][INFO][TabNet] mask_loss : -0.22246305644512177\n",
      "[2021-02-03 13:53:57,540][INFO][TabNet] time_cost : 0.019000768661499023\n",
      "[2021-02-03 13:53:57,541][INFO][TabNet] mean_squared_error : 3.4680967330932617\n",
      "[2021-02-03 13:53:57,543][INFO][TabNet] ******************** epoch : 63 ********************\n",
      "[2021-02-03 13:54:01,298][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:01,301][INFO][TabNet] total_loss : 20.863880157470703\n",
      "[2021-02-03 13:54:01,304][INFO][TabNet] task_loss : 20.86366081237793\n",
      "[2021-02-03 13:54:01,305][INFO][TabNet] mask_loss : -0.21910972893238068\n",
      "[2021-02-03 13:54:01,308][INFO][TabNet] time_cost : 0.02000260353088379\n",
      "[2021-02-03 13:54:01,310][INFO][TabNet] mean_squared_error : 3.351102113723755\n",
      "[2021-02-03 13:54:01,311][INFO][TabNet] ******************** epoch : 64 ********************\n",
      "[2021-02-03 13:54:05,012][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:05,015][INFO][TabNet] total_loss : 21.690921783447266\n",
      "[2021-02-03 13:54:05,017][INFO][TabNet] task_loss : 21.69070816040039\n",
      "[2021-02-03 13:54:05,019][INFO][TabNet] mask_loss : -0.21372906863689423\n",
      "[2021-02-03 13:54:05,021][INFO][TabNet] time_cost : 0.02299809455871582\n",
      "[2021-02-03 13:54:05,023][INFO][TabNet] mean_squared_error : 3.399972915649414\n",
      "[2021-02-03 13:54:05,025][INFO][TabNet] ******************** epoch : 65 ********************\n",
      "[2021-02-03 13:54:08,940][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:08,942][INFO][TabNet] total_loss : 17.92616081237793\n",
      "[2021-02-03 13:54:08,945][INFO][TabNet] task_loss : 17.925941467285156\n",
      "[2021-02-03 13:54:08,947][INFO][TabNet] mask_loss : -0.21947942674160004\n",
      "[2021-02-03 13:54:08,949][INFO][TabNet] time_cost : 0.021960735321044922\n",
      "[2021-02-03 13:54:08,950][INFO][TabNet] mean_squared_error : 3.2445592880249023\n",
      "[2021-02-03 13:54:08,952][INFO][TabNet] ******************** epoch : 66 ********************\n",
      "[2021-02-03 13:54:12,958][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:12,960][INFO][TabNet] total_loss : 21.013195037841797\n",
      "[2021-02-03 13:54:12,962][INFO][TabNet] task_loss : 21.012958526611328\n",
      "[2021-02-03 13:54:12,964][INFO][TabNet] mask_loss : -0.23578506708145142\n",
      "[2021-02-03 13:54:12,965][INFO][TabNet] time_cost : 0.03500032424926758\n",
      "[2021-02-03 13:54:12,967][INFO][TabNet] mean_squared_error : 3.2596235275268555\n",
      "[2021-02-03 13:54:12,968][INFO][TabNet] ******************** epoch : 67 ********************\n",
      "[2021-02-03 13:54:16,698][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:16,702][INFO][TabNet] total_loss : 23.37543487548828\n",
      "[2021-02-03 13:54:16,704][INFO][TabNet] task_loss : 23.375213623046875\n",
      "[2021-02-03 13:54:16,706][INFO][TabNet] mask_loss : -0.2210572212934494\n",
      "[2021-02-03 13:54:16,708][INFO][TabNet] time_cost : 0.020966529846191406\n",
      "[2021-02-03 13:54:16,710][INFO][TabNet] mean_squared_error : 3.518216133117676\n",
      "[2021-02-03 13:54:16,712][INFO][TabNet] ******************** epoch : 68 ********************\n",
      "[2021-02-03 13:54:20,383][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:20,385][INFO][TabNet] total_loss : 20.109838485717773\n",
      "[2021-02-03 13:54:20,388][INFO][TabNet] task_loss : 20.109609603881836\n",
      "[2021-02-03 13:54:20,389][INFO][TabNet] mask_loss : -0.2281087189912796\n",
      "[2021-02-03 13:54:20,391][INFO][TabNet] time_cost : 0.023998260498046875\n",
      "[2021-02-03 13:54:20,392][INFO][TabNet] mean_squared_error : 3.327375888824463\n",
      "[2021-02-03 13:54:20,394][INFO][TabNet] ******************** epoch : 69 ********************\n",
      "[2021-02-03 13:54:24,079][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:24,081][INFO][TabNet] total_loss : 18.478872299194336\n",
      "[2021-02-03 13:54:24,083][INFO][TabNet] task_loss : 18.4786376953125\n",
      "[2021-02-03 13:54:24,085][INFO][TabNet] mask_loss : -0.23381614685058594\n",
      "[2021-02-03 13:54:24,087][INFO][TabNet] time_cost : 0.02099895477294922\n",
      "[2021-02-03 13:54:24,089][INFO][TabNet] mean_squared_error : 3.051079511642456\n",
      "[2021-02-03 13:54:24,090][INFO][TabNet] ******************** epoch : 70 ********************\n",
      "[2021-02-03 13:54:27,764][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:27,766][INFO][TabNet] total_loss : 20.102542877197266\n",
      "[2021-02-03 13:54:27,768][INFO][TabNet] task_loss : 20.102317810058594\n",
      "[2021-02-03 13:54:27,770][INFO][TabNet] mask_loss : -0.22426468133926392\n",
      "[2021-02-03 13:54:27,771][INFO][TabNet] time_cost : 0.02892589569091797\n",
      "[2021-02-03 13:54:27,773][INFO][TabNet] mean_squared_error : 3.1913721561431885\n",
      "[2021-02-03 13:54:27,774][INFO][TabNet] ******************** epoch : 71 ********************\n",
      "[2021-02-03 13:54:32,037][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:32,039][INFO][TabNet] total_loss : 16.487079620361328\n",
      "[2021-02-03 13:54:32,041][INFO][TabNet] task_loss : 16.486846923828125\n",
      "[2021-02-03 13:54:32,042][INFO][TabNet] mask_loss : -0.2325642853975296\n",
      "[2021-02-03 13:54:32,044][INFO][TabNet] time_cost : 0.047994136810302734\n",
      "[2021-02-03 13:54:32,046][INFO][TabNet] mean_squared_error : 2.9194254875183105\n",
      "[2021-02-03 13:54:32,047][INFO][TabNet] ******************** epoch : 72 ********************\n",
      "[2021-02-03 13:54:35,893][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:35,896][INFO][TabNet] total_loss : 17.853036880493164\n",
      "[2021-02-03 13:54:35,898][INFO][TabNet] task_loss : 17.852807998657227\n",
      "[2021-02-03 13:54:35,901][INFO][TabNet] mask_loss : -0.22808140516281128\n",
      "[2021-02-03 13:54:35,903][INFO][TabNet] time_cost : 0.017000913619995117\n",
      "[2021-02-03 13:54:35,905][INFO][TabNet] mean_squared_error : 3.2318243980407715\n",
      "[2021-02-03 13:54:35,907][INFO][TabNet] ******************** epoch : 73 ********************\n",
      "[2021-02-03 13:54:39,887][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:39,890][INFO][TabNet] total_loss : 18.279674530029297\n",
      "[2021-02-03 13:54:39,892][INFO][TabNet] task_loss : 18.27944564819336\n",
      "[2021-02-03 13:54:39,894][INFO][TabNet] mask_loss : -0.2294514924287796\n",
      "[2021-02-03 13:54:39,895][INFO][TabNet] time_cost : 0.02299809455871582\n",
      "[2021-02-03 13:54:39,897][INFO][TabNet] mean_squared_error : 2.9823312759399414\n",
      "[2021-02-03 13:54:39,900][INFO][TabNet] ******************** epoch : 74 ********************\n",
      "[2021-02-03 13:54:43,716][INFO][TabNet] -------------------- train info --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:54:43,718][INFO][TabNet] total_loss : 17.445505142211914\n",
      "[2021-02-03 13:54:43,719][INFO][TabNet] task_loss : 17.445255279541016\n",
      "[2021-02-03 13:54:43,721][INFO][TabNet] mask_loss : -0.24970334768295288\n",
      "[2021-02-03 13:54:43,723][INFO][TabNet] time_cost : 0.024960041046142578\n",
      "[2021-02-03 13:54:43,724][INFO][TabNet] mean_squared_error : 3.0862293243408203\n",
      "[2021-02-03 13:54:43,726][INFO][TabNet] ******************** epoch : 75 ********************\n",
      "[2021-02-03 13:54:47,455][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:47,456][INFO][TabNet] total_loss : 14.411949157714844\n",
      "[2021-02-03 13:54:47,458][INFO][TabNet] task_loss : 14.411722183227539\n",
      "[2021-02-03 13:54:47,460][INFO][TabNet] mask_loss : -0.22668789327144623\n",
      "[2021-02-03 13:54:47,462][INFO][TabNet] time_cost : 0.027993202209472656\n",
      "[2021-02-03 13:54:47,464][INFO][TabNet] mean_squared_error : 2.8484411239624023\n",
      "[2021-02-03 13:54:47,467][INFO][TabNet] ******************** epoch : 76 ********************\n",
      "[2021-02-03 13:54:51,194][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:51,197][INFO][TabNet] total_loss : 18.36662483215332\n",
      "[2021-02-03 13:54:51,199][INFO][TabNet] task_loss : 18.366395950317383\n",
      "[2021-02-03 13:54:51,201][INFO][TabNet] mask_loss : -0.2298068404197693\n",
      "[2021-02-03 13:54:51,204][INFO][TabNet] time_cost : 0.0279998779296875\n",
      "[2021-02-03 13:54:51,205][INFO][TabNet] mean_squared_error : 2.9123334884643555\n",
      "[2021-02-03 13:54:51,208][INFO][TabNet] ******************** epoch : 77 ********************\n",
      "[2021-02-03 13:54:54,920][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:54,924][INFO][TabNet] total_loss : 19.024642944335938\n",
      "[2021-02-03 13:54:54,927][INFO][TabNet] task_loss : 19.02439308166504\n",
      "[2021-02-03 13:54:54,929][INFO][TabNet] mask_loss : -0.2490457147359848\n",
      "[2021-02-03 13:54:54,931][INFO][TabNet] time_cost : 0.02899789810180664\n",
      "[2021-02-03 13:54:54,933][INFO][TabNet] mean_squared_error : 3.0052452087402344\n",
      "[2021-02-03 13:54:54,935][INFO][TabNet] ******************** epoch : 78 ********************\n",
      "[2021-02-03 13:54:58,602][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:54:58,605][INFO][TabNet] total_loss : 15.460206985473633\n",
      "[2021-02-03 13:54:58,607][INFO][TabNet] task_loss : 15.459961891174316\n",
      "[2021-02-03 13:54:58,609][INFO][TabNet] mask_loss : -0.2447042018175125\n",
      "[2021-02-03 13:54:58,612][INFO][TabNet] time_cost : 0.017999887466430664\n",
      "[2021-02-03 13:54:58,614][INFO][TabNet] mean_squared_error : 2.941840887069702\n",
      "[2021-02-03 13:54:58,617][INFO][TabNet] ******************** epoch : 79 ********************\n",
      "[2021-02-03 13:55:02,324][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:02,327][INFO][TabNet] total_loss : 14.75055980682373\n",
      "[2021-02-03 13:55:02,328][INFO][TabNet] task_loss : 14.750317573547363\n",
      "[2021-02-03 13:55:02,330][INFO][TabNet] mask_loss : -0.2423538714647293\n",
      "[2021-02-03 13:55:02,332][INFO][TabNet] time_cost : 0.01699352264404297\n",
      "[2021-02-03 13:55:02,333][INFO][TabNet] mean_squared_error : 2.9265646934509277\n",
      "[2021-02-03 13:55:02,334][INFO][TabNet] ******************** epoch : 80 ********************\n",
      "[2021-02-03 13:55:06,036][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:06,039][INFO][TabNet] total_loss : 19.10285758972168\n",
      "[2021-02-03 13:55:06,041][INFO][TabNet] task_loss : 19.10262680053711\n",
      "[2021-02-03 13:55:06,044][INFO][TabNet] mask_loss : -0.22999005019664764\n",
      "[2021-02-03 13:55:06,046][INFO][TabNet] time_cost : 0.02799057960510254\n",
      "[2021-02-03 13:55:06,048][INFO][TabNet] mean_squared_error : 3.1682839393615723\n",
      "[2021-02-03 13:55:06,050][INFO][TabNet] ******************** epoch : 81 ********************\n",
      "[2021-02-03 13:55:09,822][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:09,824][INFO][TabNet] total_loss : 22.2559871673584\n",
      "[2021-02-03 13:55:09,827][INFO][TabNet] task_loss : 22.255739212036133\n",
      "[2021-02-03 13:55:09,829][INFO][TabNet] mask_loss : -0.24785004556179047\n",
      "[2021-02-03 13:55:09,830][INFO][TabNet] time_cost : 0.021996021270751953\n",
      "[2021-02-03 13:55:09,832][INFO][TabNet] mean_squared_error : 3.3423843383789062\n",
      "[2021-02-03 13:55:09,833][INFO][TabNet] ******************** epoch : 82 ********************\n",
      "[2021-02-03 13:55:13,913][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:13,915][INFO][TabNet] total_loss : 16.897619247436523\n",
      "[2021-02-03 13:55:13,916][INFO][TabNet] task_loss : 16.89739227294922\n",
      "[2021-02-03 13:55:13,918][INFO][TabNet] mask_loss : -0.22696363925933838\n",
      "[2021-02-03 13:55:13,919][INFO][TabNet] time_cost : 0.021004438400268555\n",
      "[2021-02-03 13:55:13,921][INFO][TabNet] mean_squared_error : 2.9803614616394043\n",
      "[2021-02-03 13:55:13,923][INFO][TabNet] ******************** epoch : 83 ********************\n",
      "[2021-02-03 13:55:18,002][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:18,004][INFO][TabNet] total_loss : 16.834535598754883\n",
      "[2021-02-03 13:55:18,006][INFO][TabNet] task_loss : 16.83429527282715\n",
      "[2021-02-03 13:55:18,008][INFO][TabNet] mask_loss : -0.24075545370578766\n",
      "[2021-02-03 13:55:18,010][INFO][TabNet] time_cost : 0.02000117301940918\n",
      "[2021-02-03 13:55:18,012][INFO][TabNet] mean_squared_error : 3.095709800720215\n",
      "[2021-02-03 13:55:18,014][INFO][TabNet] ******************** epoch : 84 ********************\n",
      "[2021-02-03 13:55:22,793][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:22,795][INFO][TabNet] total_loss : 15.707592964172363\n",
      "[2021-02-03 13:55:22,797][INFO][TabNet] task_loss : 15.707353591918945\n",
      "[2021-02-03 13:55:22,799][INFO][TabNet] mask_loss : -0.23923484981060028\n",
      "[2021-02-03 13:55:22,801][INFO][TabNet] time_cost : 0.029999494552612305\n",
      "[2021-02-03 13:55:22,802][INFO][TabNet] mean_squared_error : 2.9109346866607666\n",
      "[2021-02-03 13:55:22,804][INFO][TabNet] ******************** epoch : 85 ********************\n",
      "[2021-02-03 13:55:26,897][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:26,899][INFO][TabNet] total_loss : 16.992095947265625\n",
      "[2021-02-03 13:55:26,901][INFO][TabNet] task_loss : 16.99184799194336\n",
      "[2021-02-03 13:55:26,902][INFO][TabNet] mask_loss : -0.24842523038387299\n",
      "[2021-02-03 13:55:26,904][INFO][TabNet] time_cost : 0.03099679946899414\n",
      "[2021-02-03 13:55:26,906][INFO][TabNet] mean_squared_error : 3.0569586753845215\n",
      "[2021-02-03 13:55:26,907][INFO][TabNet] ******************** epoch : 86 ********************\n",
      "[2021-02-03 13:55:30,924][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:30,926][INFO][TabNet] total_loss : 18.390674591064453\n",
      "[2021-02-03 13:55:30,928][INFO][TabNet] task_loss : 18.390417098999023\n",
      "[2021-02-03 13:55:30,930][INFO][TabNet] mask_loss : -0.2569313645362854\n",
      "[2021-02-03 13:55:30,931][INFO][TabNet] time_cost : 0.02099776268005371\n",
      "[2021-02-03 13:55:30,933][INFO][TabNet] mean_squared_error : 3.087374687194824\n",
      "[2021-02-03 13:55:30,934][INFO][TabNet] ******************** epoch : 87 ********************\n",
      "[2021-02-03 13:55:35,155][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:35,158][INFO][TabNet] total_loss : 18.897863388061523\n",
      "[2021-02-03 13:55:35,161][INFO][TabNet] task_loss : 18.89761734008789\n",
      "[2021-02-03 13:55:35,164][INFO][TabNet] mask_loss : -0.24636457860469818\n",
      "[2021-02-03 13:55:35,166][INFO][TabNet] time_cost : 0.04199552536010742\n",
      "[2021-02-03 13:55:35,168][INFO][TabNet] mean_squared_error : 3.073253631591797\n",
      "[2021-02-03 13:55:35,170][INFO][TabNet] ******************** epoch : 88 ********************\n",
      "[2021-02-03 13:55:39,377][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:39,381][INFO][TabNet] total_loss : 14.517611503601074\n",
      "[2021-02-03 13:55:39,383][INFO][TabNet] task_loss : 14.517363548278809\n",
      "[2021-02-03 13:55:39,386][INFO][TabNet] mask_loss : -0.24814824759960175\n",
      "[2021-02-03 13:55:39,388][INFO][TabNet] time_cost : 0.0229952335357666\n",
      "[2021-02-03 13:55:39,390][INFO][TabNet] mean_squared_error : 2.9304323196411133\n",
      "[2021-02-03 13:55:39,392][INFO][TabNet] ******************** epoch : 89 ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:55:43,133][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:43,137][INFO][TabNet] total_loss : 16.905546188354492\n",
      "[2021-02-03 13:55:43,139][INFO][TabNet] task_loss : 16.90530014038086\n",
      "[2021-02-03 13:55:43,141][INFO][TabNet] mask_loss : -0.24674147367477417\n",
      "[2021-02-03 13:55:43,142][INFO][TabNet] time_cost : 0.021999835968017578\n",
      "[2021-02-03 13:55:43,144][INFO][TabNet] mean_squared_error : 2.9090943336486816\n",
      "[2021-02-03 13:55:43,146][INFO][TabNet] ******************** epoch : 90 ********************\n",
      "[2021-02-03 13:55:46,880][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:46,882][INFO][TabNet] total_loss : 17.463722229003906\n",
      "[2021-02-03 13:55:46,884][INFO][TabNet] task_loss : 17.46347427368164\n",
      "[2021-02-03 13:55:46,886][INFO][TabNet] mask_loss : -0.2481185644865036\n",
      "[2021-02-03 13:55:46,888][INFO][TabNet] time_cost : 0.02499556541442871\n",
      "[2021-02-03 13:55:46,890][INFO][TabNet] mean_squared_error : 2.9528121948242188\n",
      "[2021-02-03 13:55:46,891][INFO][TabNet] ******************** epoch : 91 ********************\n",
      "[2021-02-03 13:55:50,620][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:50,623][INFO][TabNet] total_loss : 18.159154891967773\n",
      "[2021-02-03 13:55:50,626][INFO][TabNet] task_loss : 18.158903121948242\n",
      "[2021-02-03 13:55:50,628][INFO][TabNet] mask_loss : -0.2527206242084503\n",
      "[2021-02-03 13:55:50,630][INFO][TabNet] time_cost : 0.027963638305664062\n",
      "[2021-02-03 13:55:50,633][INFO][TabNet] mean_squared_error : 3.044050693511963\n",
      "[2021-02-03 13:55:50,635][INFO][TabNet] ******************** epoch : 92 ********************\n",
      "[2021-02-03 13:55:54,326][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:54,329][INFO][TabNet] total_loss : 16.29714584350586\n",
      "[2021-02-03 13:55:54,331][INFO][TabNet] task_loss : 16.296894073486328\n",
      "[2021-02-03 13:55:54,333][INFO][TabNet] mask_loss : -0.25174853205680847\n",
      "[2021-02-03 13:55:54,334][INFO][TabNet] time_cost : 0.018000364303588867\n",
      "[2021-02-03 13:55:54,336][INFO][TabNet] mean_squared_error : 2.998197317123413\n",
      "[2021-02-03 13:55:54,337][INFO][TabNet] ******************** epoch : 93 ********************\n",
      "[2021-02-03 13:55:58,037][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:55:58,040][INFO][TabNet] total_loss : 12.904027938842773\n",
      "[2021-02-03 13:55:58,042][INFO][TabNet] task_loss : 12.90375804901123\n",
      "[2021-02-03 13:55:58,044][INFO][TabNet] mask_loss : -0.2698083221912384\n",
      "[2021-02-03 13:55:58,045][INFO][TabNet] time_cost : 0.02299809455871582\n",
      "[2021-02-03 13:55:58,047][INFO][TabNet] mean_squared_error : 2.7948033809661865\n",
      "[2021-02-03 13:55:58,048][INFO][TabNet] ******************** epoch : 94 ********************\n",
      "[2021-02-03 13:56:01,818][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:01,820][INFO][TabNet] total_loss : 17.969205856323242\n",
      "[2021-02-03 13:56:01,822][INFO][TabNet] task_loss : 17.96894073486328\n",
      "[2021-02-03 13:56:01,824][INFO][TabNet] mask_loss : -0.26434239745140076\n",
      "[2021-02-03 13:56:01,825][INFO][TabNet] time_cost : 0.02799510955810547\n",
      "[2021-02-03 13:56:01,827][INFO][TabNet] mean_squared_error : 3.018214225769043\n",
      "[2021-02-03 13:56:01,829][INFO][TabNet] ******************** epoch : 95 ********************\n",
      "[2021-02-03 13:56:05,535][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:05,537][INFO][TabNet] total_loss : 19.69527816772461\n",
      "[2021-02-03 13:56:05,539][INFO][TabNet] task_loss : 19.69501495361328\n",
      "[2021-02-03 13:56:05,541][INFO][TabNet] mask_loss : -0.2630346119403839\n",
      "[2021-02-03 13:56:05,543][INFO][TabNet] time_cost : 0.020969390869140625\n",
      "[2021-02-03 13:56:05,544][INFO][TabNet] mean_squared_error : 3.1163828372955322\n",
      "[2021-02-03 13:56:05,546][INFO][TabNet] ******************** epoch : 96 ********************\n",
      "[2021-02-03 13:56:09,244][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:09,246][INFO][TabNet] total_loss : 20.423439025878906\n",
      "[2021-02-03 13:56:09,248][INFO][TabNet] task_loss : 20.423171997070312\n",
      "[2021-02-03 13:56:09,249][INFO][TabNet] mask_loss : -0.2669319808483124\n",
      "[2021-02-03 13:56:09,251][INFO][TabNet] time_cost : 0.01997518539428711\n",
      "[2021-02-03 13:56:09,252][INFO][TabNet] mean_squared_error : 3.055522918701172\n",
      "[2021-02-03 13:56:09,253][INFO][TabNet] ******************** epoch : 97 ********************\n",
      "[2021-02-03 13:56:12,957][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:12,960][INFO][TabNet] total_loss : 14.924701690673828\n",
      "[2021-02-03 13:56:12,962][INFO][TabNet] task_loss : 14.924446105957031\n",
      "[2021-02-03 13:56:12,964][INFO][TabNet] mask_loss : -0.2551380395889282\n",
      "[2021-02-03 13:56:12,966][INFO][TabNet] time_cost : 0.01999807357788086\n",
      "[2021-02-03 13:56:12,967][INFO][TabNet] mean_squared_error : 2.8099403381347656\n",
      "[2021-02-03 13:56:12,969][INFO][TabNet] ******************** epoch : 98 ********************\n",
      "[2021-02-03 13:56:16,634][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:16,636][INFO][TabNet] total_loss : 16.666147232055664\n",
      "[2021-02-03 13:56:16,639][INFO][TabNet] task_loss : 16.6658878326416\n",
      "[2021-02-03 13:56:16,644][INFO][TabNet] mask_loss : -0.259650319814682\n",
      "[2021-02-03 13:56:16,645][INFO][TabNet] time_cost : 0.026995182037353516\n",
      "[2021-02-03 13:56:16,647][INFO][TabNet] mean_squared_error : 3.0555667877197266\n",
      "[2021-02-03 13:56:16,649][INFO][TabNet] ******************** epoch : 99 ********************\n",
      "[2021-02-03 13:56:20,357][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:20,360][INFO][TabNet] total_loss : 16.94414710998535\n",
      "[2021-02-03 13:56:20,363][INFO][TabNet] task_loss : 16.943891525268555\n",
      "[2021-02-03 13:56:20,365][INFO][TabNet] mask_loss : -0.25470075011253357\n",
      "[2021-02-03 13:56:20,367][INFO][TabNet] time_cost : 0.02199840545654297\n",
      "[2021-02-03 13:56:20,369][INFO][TabNet] mean_squared_error : 3.012518882751465\n",
      "[2021-02-03 13:56:20,371][INFO][TabNet] ******************** epoch : 100 ********************\n",
      "[2021-02-03 13:56:24,401][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:24,403][INFO][TabNet] total_loss : 19.033531188964844\n",
      "[2021-02-03 13:56:24,404][INFO][TabNet] task_loss : 19.033279418945312\n",
      "[2021-02-03 13:56:24,406][INFO][TabNet] mask_loss : -0.25203633308410645\n",
      "[2021-02-03 13:56:24,408][INFO][TabNet] time_cost : 0.032997846603393555\n",
      "[2021-02-03 13:56:24,409][INFO][TabNet] mean_squared_error : 3.1660871505737305\n",
      "[2021-02-03 13:56:24,411][INFO][TabNet] ******************** epoch : 101 ********************\n",
      "[2021-02-03 13:56:28,255][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:28,258][INFO][TabNet] total_loss : 16.225492477416992\n",
      "[2021-02-03 13:56:28,260][INFO][TabNet] task_loss : 16.225231170654297\n",
      "[2021-02-03 13:56:28,263][INFO][TabNet] mask_loss : -0.2611196041107178\n",
      "[2021-02-03 13:56:28,264][INFO][TabNet] time_cost : 0.02499532699584961\n",
      "[2021-02-03 13:56:28,266][INFO][TabNet] mean_squared_error : 2.790862560272217\n",
      "[2021-02-03 13:56:28,267][INFO][TabNet] ******************** epoch : 102 ********************\n",
      "[2021-02-03 13:56:31,953][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:31,955][INFO][TabNet] total_loss : 19.10041046142578\n",
      "[2021-02-03 13:56:31,958][INFO][TabNet] task_loss : 19.10015296936035\n",
      "[2021-02-03 13:56:31,960][INFO][TabNet] mask_loss : -0.25684654712677\n",
      "[2021-02-03 13:56:31,962][INFO][TabNet] time_cost : 0.023955821990966797\n",
      "[2021-02-03 13:56:31,963][INFO][TabNet] mean_squared_error : 3.052460193634033\n",
      "[2021-02-03 13:56:31,965][INFO][TabNet] ******************** epoch : 103 ********************\n",
      "[2021-02-03 13:56:35,679][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:35,680][INFO][TabNet] total_loss : 16.325883865356445\n",
      "[2021-02-03 13:56:35,682][INFO][TabNet] task_loss : 16.32563018798828\n",
      "[2021-02-03 13:56:35,685][INFO][TabNet] mask_loss : -0.25372883677482605\n",
      "[2021-02-03 13:56:35,687][INFO][TabNet] time_cost : 0.02596449851989746\n",
      "[2021-02-03 13:56:35,689][INFO][TabNet] mean_squared_error : 2.981703519821167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:56:35,691][INFO][TabNet] ******************** epoch : 104 ********************\n",
      "[2021-02-03 13:56:39,400][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:39,402][INFO][TabNet] total_loss : 15.460806846618652\n",
      "[2021-02-03 13:56:39,404][INFO][TabNet] task_loss : 15.460545539855957\n",
      "[2021-02-03 13:56:39,406][INFO][TabNet] mask_loss : -0.2609458565711975\n",
      "[2021-02-03 13:56:39,407][INFO][TabNet] time_cost : 0.02095317840576172\n",
      "[2021-02-03 13:56:39,409][INFO][TabNet] mean_squared_error : 2.8335843086242676\n",
      "[2021-02-03 13:56:39,411][INFO][TabNet] ******************** epoch : 105 ********************\n",
      "[2021-02-03 13:56:43,104][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:43,107][INFO][TabNet] total_loss : 16.49391746520996\n",
      "[2021-02-03 13:56:43,109][INFO][TabNet] task_loss : 16.49365997314453\n",
      "[2021-02-03 13:56:43,111][INFO][TabNet] mask_loss : -0.25751611590385437\n",
      "[2021-02-03 13:56:43,113][INFO][TabNet] time_cost : 0.026996135711669922\n",
      "[2021-02-03 13:56:43,115][INFO][TabNet] mean_squared_error : 2.8085384368896484\n",
      "[2021-02-03 13:56:43,116][INFO][TabNet] ******************** epoch : 106 ********************\n",
      "[2021-02-03 13:56:46,838][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:46,840][INFO][TabNet] total_loss : 12.002679824829102\n",
      "[2021-02-03 13:56:46,842][INFO][TabNet] task_loss : 12.002413749694824\n",
      "[2021-02-03 13:56:46,844][INFO][TabNet] mask_loss : -0.2662234604358673\n",
      "[2021-02-03 13:56:46,846][INFO][TabNet] time_cost : 0.027996301651000977\n",
      "[2021-02-03 13:56:46,848][INFO][TabNet] mean_squared_error : 2.643105983734131\n",
      "[2021-02-03 13:56:46,849][INFO][TabNet] ******************** epoch : 107 ********************\n",
      "[2021-02-03 13:56:50,567][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:50,570][INFO][TabNet] total_loss : 18.485212326049805\n",
      "[2021-02-03 13:56:50,572][INFO][TabNet] task_loss : 18.48495101928711\n",
      "[2021-02-03 13:56:50,575][INFO][TabNet] mask_loss : -0.2613847553730011\n",
      "[2021-02-03 13:56:50,577][INFO][TabNet] time_cost : 0.018995285034179688\n",
      "[2021-02-03 13:56:50,579][INFO][TabNet] mean_squared_error : 3.034672260284424\n",
      "[2021-02-03 13:56:50,580][INFO][TabNet] ******************** epoch : 108 ********************\n",
      "[2021-02-03 13:56:54,306][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:54,308][INFO][TabNet] total_loss : 12.987866401672363\n",
      "[2021-02-03 13:56:54,310][INFO][TabNet] task_loss : 12.987597465515137\n",
      "[2021-02-03 13:56:54,313][INFO][TabNet] mask_loss : -0.2692374289035797\n",
      "[2021-02-03 13:56:54,314][INFO][TabNet] time_cost : 0.027983903884887695\n",
      "[2021-02-03 13:56:54,316][INFO][TabNet] mean_squared_error : 2.7070679664611816\n",
      "[2021-02-03 13:56:54,318][INFO][TabNet] ******************** epoch : 109 ********************\n",
      "[2021-02-03 13:56:58,013][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:56:58,016][INFO][TabNet] total_loss : 22.34012794494629\n",
      "[2021-02-03 13:56:58,018][INFO][TabNet] task_loss : 22.339874267578125\n",
      "[2021-02-03 13:56:58,020][INFO][TabNet] mask_loss : -0.2528001070022583\n",
      "[2021-02-03 13:56:58,022][INFO][TabNet] time_cost : 0.023002147674560547\n",
      "[2021-02-03 13:56:58,023][INFO][TabNet] mean_squared_error : 3.353790283203125\n",
      "[2021-02-03 13:56:58,024][INFO][TabNet] ******************** epoch : 110 ********************\n",
      "[2021-02-03 13:57:01,778][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:01,780][INFO][TabNet] total_loss : 18.078845977783203\n",
      "[2021-02-03 13:57:01,781][INFO][TabNet] task_loss : 18.078575134277344\n",
      "[2021-02-03 13:57:01,782][INFO][TabNet] mask_loss : -0.27161136269569397\n",
      "[2021-02-03 13:57:01,784][INFO][TabNet] time_cost : 0.021001577377319336\n",
      "[2021-02-03 13:57:01,785][INFO][TabNet] mean_squared_error : 2.8988399505615234\n",
      "[2021-02-03 13:57:01,787][INFO][TabNet] ******************** epoch : 111 ********************\n",
      "[2021-02-03 13:57:05,851][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:05,853][INFO][TabNet] total_loss : 16.928476333618164\n",
      "[2021-02-03 13:57:05,855][INFO][TabNet] task_loss : 16.928213119506836\n",
      "[2021-02-03 13:57:05,856][INFO][TabNet] mask_loss : -0.2636507749557495\n",
      "[2021-02-03 13:57:05,858][INFO][TabNet] time_cost : 0.029998302459716797\n",
      "[2021-02-03 13:57:05,859][INFO][TabNet] mean_squared_error : 2.873249053955078\n",
      "[2021-02-03 13:57:05,861][INFO][TabNet] ******************** epoch : 112 ********************\n",
      "[2021-02-03 13:57:09,594][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:09,597][INFO][TabNet] total_loss : 11.346087455749512\n",
      "[2021-02-03 13:57:09,600][INFO][TabNet] task_loss : 11.345810890197754\n",
      "[2021-02-03 13:57:09,602][INFO][TabNet] mask_loss : -0.2764274775981903\n",
      "[2021-02-03 13:57:09,604][INFO][TabNet] time_cost : 0.020001649856567383\n",
      "[2021-02-03 13:57:09,607][INFO][TabNet] mean_squared_error : 2.679013729095459\n",
      "[2021-02-03 13:57:09,609][INFO][TabNet] ******************** epoch : 113 ********************\n",
      "[2021-02-03 13:57:13,473][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:13,474][INFO][TabNet] total_loss : 18.500219345092773\n",
      "[2021-02-03 13:57:13,476][INFO][TabNet] task_loss : 18.499956130981445\n",
      "[2021-02-03 13:57:13,477][INFO][TabNet] mask_loss : -0.26414361596107483\n",
      "[2021-02-03 13:57:13,479][INFO][TabNet] time_cost : 0.01799798011779785\n",
      "[2021-02-03 13:57:13,481][INFO][TabNet] mean_squared_error : 2.925769805908203\n",
      "[2021-02-03 13:57:13,482][INFO][TabNet] ******************** epoch : 114 ********************\n",
      "[2021-02-03 13:57:17,369][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:17,373][INFO][TabNet] total_loss : 14.271602630615234\n",
      "[2021-02-03 13:57:17,376][INFO][TabNet] task_loss : 14.271340370178223\n",
      "[2021-02-03 13:57:17,378][INFO][TabNet] mask_loss : -0.2619750499725342\n",
      "[2021-02-03 13:57:17,380][INFO][TabNet] time_cost : 0.024980545043945312\n",
      "[2021-02-03 13:57:17,381][INFO][TabNet] mean_squared_error : 2.854100227355957\n",
      "[2021-02-03 13:57:17,383][INFO][TabNet] ******************** epoch : 115 ********************\n",
      "[2021-02-03 13:57:21,091][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:21,093][INFO][TabNet] total_loss : 15.486363410949707\n",
      "[2021-02-03 13:57:21,095][INFO][TabNet] task_loss : 15.486080169677734\n",
      "[2021-02-03 13:57:21,097][INFO][TabNet] mask_loss : -0.2832637429237366\n",
      "[2021-02-03 13:57:21,099][INFO][TabNet] time_cost : 0.021002531051635742\n",
      "[2021-02-03 13:57:21,100][INFO][TabNet] mean_squared_error : 2.801309108734131\n",
      "[2021-02-03 13:57:21,102][INFO][TabNet] ******************** epoch : 116 ********************\n",
      "[2021-02-03 13:57:24,847][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:24,850][INFO][TabNet] total_loss : 13.073756217956543\n",
      "[2021-02-03 13:57:24,852][INFO][TabNet] task_loss : 13.073502540588379\n",
      "[2021-02-03 13:57:24,855][INFO][TabNet] mask_loss : -0.25370481610298157\n",
      "[2021-02-03 13:57:24,856][INFO][TabNet] time_cost : 0.027997732162475586\n",
      "[2021-02-03 13:57:24,858][INFO][TabNet] mean_squared_error : 2.6944448947906494\n",
      "[2021-02-03 13:57:24,859][INFO][TabNet] ******************** epoch : 117 ********************\n",
      "[2021-02-03 13:57:28,917][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:28,920][INFO][TabNet] total_loss : 14.068603515625\n",
      "[2021-02-03 13:57:28,923][INFO][TabNet] task_loss : 14.068342208862305\n",
      "[2021-02-03 13:57:28,925][INFO][TabNet] mask_loss : -0.26175037026405334\n",
      "[2021-02-03 13:57:28,928][INFO][TabNet] time_cost : 0.022001266479492188\n",
      "[2021-02-03 13:57:28,930][INFO][TabNet] mean_squared_error : 2.7572617530822754\n",
      "[2021-02-03 13:57:28,932][INFO][TabNet] ******************** epoch : 118 ********************\n",
      "[2021-02-03 13:57:32,864][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:32,867][INFO][TabNet] total_loss : 18.666471481323242\n",
      "[2021-02-03 13:57:32,869][INFO][TabNet] task_loss : 18.666194915771484\n",
      "[2021-02-03 13:57:32,871][INFO][TabNet] mask_loss : -0.27596476674079895\n",
      "[2021-02-03 13:57:32,873][INFO][TabNet] time_cost : 0.02196669578552246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:57:32,875][INFO][TabNet] mean_squared_error : 2.931251287460327\n",
      "[2021-02-03 13:57:32,877][INFO][TabNet] ******************** epoch : 119 ********************\n",
      "[2021-02-03 13:57:36,620][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:36,622][INFO][TabNet] total_loss : 14.832707405090332\n",
      "[2021-02-03 13:57:36,624][INFO][TabNet] task_loss : 14.832435607910156\n",
      "[2021-02-03 13:57:36,626][INFO][TabNet] mask_loss : -0.27163681387901306\n",
      "[2021-02-03 13:57:36,627][INFO][TabNet] time_cost : 0.021959781646728516\n",
      "[2021-02-03 13:57:36,629][INFO][TabNet] mean_squared_error : 2.8603992462158203\n",
      "[2021-02-03 13:57:36,631][INFO][TabNet] ******************** epoch : 120 ********************\n",
      "[2021-02-03 13:57:40,312][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:40,314][INFO][TabNet] total_loss : 15.651037216186523\n",
      "[2021-02-03 13:57:40,316][INFO][TabNet] task_loss : 15.650775909423828\n",
      "[2021-02-03 13:57:40,318][INFO][TabNet] mask_loss : -0.2612515985965729\n",
      "[2021-02-03 13:57:40,320][INFO][TabNet] time_cost : 0.02199721336364746\n",
      "[2021-02-03 13:57:40,321][INFO][TabNet] mean_squared_error : 2.7826032638549805\n",
      "[2021-02-03 13:57:40,323][INFO][TabNet] ******************** epoch : 121 ********************\n",
      "[2021-02-03 13:57:44,038][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:44,040][INFO][TabNet] total_loss : 13.774297714233398\n",
      "[2021-02-03 13:57:44,043][INFO][TabNet] task_loss : 13.774039268493652\n",
      "[2021-02-03 13:57:44,045][INFO][TabNet] mask_loss : -0.25853127241134644\n",
      "[2021-02-03 13:57:44,046][INFO][TabNet] time_cost : 0.028002500534057617\n",
      "[2021-02-03 13:57:44,048][INFO][TabNet] mean_squared_error : 2.609203338623047\n",
      "[2021-02-03 13:57:44,049][INFO][TabNet] ******************** epoch : 122 ********************\n",
      "[2021-02-03 13:57:47,749][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:47,751][INFO][TabNet] total_loss : 15.459864616394043\n",
      "[2021-02-03 13:57:47,754][INFO][TabNet] task_loss : 15.459595680236816\n",
      "[2021-02-03 13:57:47,755][INFO][TabNet] mask_loss : -0.2692347764968872\n",
      "[2021-02-03 13:57:47,758][INFO][TabNet] time_cost : 0.01900458335876465\n",
      "[2021-02-03 13:57:47,760][INFO][TabNet] mean_squared_error : 3.067866325378418\n",
      "[2021-02-03 13:57:47,761][INFO][TabNet] ******************** epoch : 123 ********************\n",
      "[2021-02-03 13:57:51,539][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:51,541][INFO][TabNet] total_loss : 18.30780601501465\n",
      "[2021-02-03 13:57:51,542][INFO][TabNet] task_loss : 18.307538986206055\n",
      "[2021-02-03 13:57:51,544][INFO][TabNet] mask_loss : -0.2669790983200073\n",
      "[2021-02-03 13:57:51,546][INFO][TabNet] time_cost : 0.02899336814880371\n",
      "[2021-02-03 13:57:51,547][INFO][TabNet] mean_squared_error : 3.007880210876465\n",
      "[2021-02-03 13:57:51,549][INFO][TabNet] ******************** epoch : 124 ********************\n",
      "[2021-02-03 13:57:55,262][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:55,265][INFO][TabNet] total_loss : 11.660713195800781\n",
      "[2021-02-03 13:57:55,267][INFO][TabNet] task_loss : 11.660453796386719\n",
      "[2021-02-03 13:57:55,269][INFO][TabNet] mask_loss : -0.2590389847755432\n",
      "[2021-02-03 13:57:55,271][INFO][TabNet] time_cost : 0.021002531051635742\n",
      "[2021-02-03 13:57:55,273][INFO][TabNet] mean_squared_error : 2.628037452697754\n",
      "[2021-02-03 13:57:55,275][INFO][TabNet] ******************** epoch : 125 ********************\n",
      "[2021-02-03 13:57:59,056][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:57:59,058][INFO][TabNet] total_loss : 15.082342147827148\n",
      "[2021-02-03 13:57:59,059][INFO][TabNet] task_loss : 15.082072257995605\n",
      "[2021-02-03 13:57:59,061][INFO][TabNet] mask_loss : -0.2695761024951935\n",
      "[2021-02-03 13:57:59,063][INFO][TabNet] time_cost : 0.024996042251586914\n",
      "[2021-02-03 13:57:59,065][INFO][TabNet] mean_squared_error : 2.8708269596099854\n",
      "[2021-02-03 13:57:59,066][INFO][TabNet] ******************** epoch : 126 ********************\n",
      "[2021-02-03 13:58:02,918][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:02,921][INFO][TabNet] total_loss : 16.153560638427734\n",
      "[2021-02-03 13:58:02,923][INFO][TabNet] task_loss : 16.153301239013672\n",
      "[2021-02-03 13:58:02,925][INFO][TabNet] mask_loss : -0.25854259729385376\n",
      "[2021-02-03 13:58:02,926][INFO][TabNet] time_cost : 0.027995824813842773\n",
      "[2021-02-03 13:58:02,928][INFO][TabNet] mean_squared_error : 2.7145962715148926\n",
      "[2021-02-03 13:58:02,929][INFO][TabNet] ******************** epoch : 127 ********************\n",
      "[2021-02-03 13:58:06,737][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:06,739][INFO][TabNet] total_loss : 17.20647621154785\n",
      "[2021-02-03 13:58:06,741][INFO][TabNet] task_loss : 17.206214904785156\n",
      "[2021-02-03 13:58:06,742][INFO][TabNet] mask_loss : -0.2610915005207062\n",
      "[2021-02-03 13:58:06,744][INFO][TabNet] time_cost : 0.021996736526489258\n",
      "[2021-02-03 13:58:06,745][INFO][TabNet] mean_squared_error : 2.876082420349121\n",
      "[2021-02-03 13:58:06,747][INFO][TabNet] ******************** epoch : 128 ********************\n",
      "[2021-02-03 13:58:10,648][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:10,650][INFO][TabNet] total_loss : 11.509047508239746\n",
      "[2021-02-03 13:58:10,651][INFO][TabNet] task_loss : 11.508790969848633\n",
      "[2021-02-03 13:58:10,653][INFO][TabNet] mask_loss : -0.256089448928833\n",
      "[2021-02-03 13:58:10,655][INFO][TabNet] time_cost : 0.02299976348876953\n",
      "[2021-02-03 13:58:10,656][INFO][TabNet] mean_squared_error : 2.6433229446411133\n",
      "[2021-02-03 13:58:10,659][INFO][TabNet] ******************** epoch : 129 ********************\n",
      "[2021-02-03 13:58:14,608][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:14,611][INFO][TabNet] total_loss : 14.912994384765625\n",
      "[2021-02-03 13:58:14,612][INFO][TabNet] task_loss : 14.912721633911133\n",
      "[2021-02-03 13:58:14,614][INFO][TabNet] mask_loss : -0.27255359292030334\n",
      "[2021-02-03 13:58:14,616][INFO][TabNet] time_cost : 0.02195906639099121\n",
      "[2021-02-03 13:58:14,617][INFO][TabNet] mean_squared_error : 2.712512493133545\n",
      "[2021-02-03 13:58:14,619][INFO][TabNet] ******************** epoch : 130 ********************\n",
      "[2021-02-03 13:58:18,643][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:18,645][INFO][TabNet] total_loss : 17.89751434326172\n",
      "[2021-02-03 13:58:18,646][INFO][TabNet] task_loss : 17.897254943847656\n",
      "[2021-02-03 13:58:18,647][INFO][TabNet] mask_loss : -0.2586694657802582\n",
      "[2021-02-03 13:58:18,649][INFO][TabNet] time_cost : 0.02399897575378418\n",
      "[2021-02-03 13:58:18,651][INFO][TabNet] mean_squared_error : 2.949373245239258\n",
      "[2021-02-03 13:58:18,652][INFO][TabNet] ******************** epoch : 131 ********************\n",
      "[2021-02-03 13:58:22,553][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:22,556][INFO][TabNet] total_loss : 16.619434356689453\n",
      "[2021-02-03 13:58:22,558][INFO][TabNet] task_loss : 16.61918067932129\n",
      "[2021-02-03 13:58:22,561][INFO][TabNet] mask_loss : -0.25426849722862244\n",
      "[2021-02-03 13:58:22,563][INFO][TabNet] time_cost : 0.027998685836791992\n",
      "[2021-02-03 13:58:22,565][INFO][TabNet] mean_squared_error : 2.91257381439209\n",
      "[2021-02-03 13:58:22,567][INFO][TabNet] ******************** epoch : 132 ********************\n",
      "[2021-02-03 13:58:26,303][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:26,307][INFO][TabNet] total_loss : 18.508806228637695\n",
      "[2021-02-03 13:58:26,309][INFO][TabNet] task_loss : 18.508556365966797\n",
      "[2021-02-03 13:58:26,312][INFO][TabNet] mask_loss : -0.24981220066547394\n",
      "[2021-02-03 13:58:26,314][INFO][TabNet] time_cost : 0.021999835968017578\n",
      "[2021-02-03 13:58:26,315][INFO][TabNet] mean_squared_error : 3.0274415016174316\n",
      "[2021-02-03 13:58:26,318][INFO][TabNet] ******************** epoch : 133 ********************\n",
      "[2021-02-03 13:58:30,308][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:30,310][INFO][TabNet] total_loss : 13.0330228805542\n",
      "[2021-02-03 13:58:30,311][INFO][TabNet] task_loss : 13.032767295837402\n",
      "[2021-02-03 13:58:30,313][INFO][TabNet] mask_loss : -0.2556544244289398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:58:30,315][INFO][TabNet] time_cost : 0.02500176429748535\n",
      "[2021-02-03 13:58:30,317][INFO][TabNet] mean_squared_error : 2.664052963256836\n",
      "[2021-02-03 13:58:30,319][INFO][TabNet] ******************** epoch : 134 ********************\n",
      "[2021-02-03 13:58:34,202][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:34,205][INFO][TabNet] total_loss : 22.309329986572266\n",
      "[2021-02-03 13:58:34,210][INFO][TabNet] task_loss : 22.30907440185547\n",
      "[2021-02-03 13:58:34,213][INFO][TabNet] mask_loss : -0.25511041283607483\n",
      "[2021-02-03 13:58:34,216][INFO][TabNet] time_cost : 0.02399277687072754\n",
      "[2021-02-03 13:58:34,218][INFO][TabNet] mean_squared_error : 3.3356738090515137\n",
      "[2021-02-03 13:58:34,221][INFO][TabNet] ******************** epoch : 135 ********************\n",
      "[2021-02-03 13:58:38,424][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:38,425][INFO][TabNet] total_loss : 17.701335906982422\n",
      "[2021-02-03 13:58:38,427][INFO][TabNet] task_loss : 17.701068878173828\n",
      "[2021-02-03 13:58:38,429][INFO][TabNet] mask_loss : -0.26794394850730896\n",
      "[2021-02-03 13:58:38,430][INFO][TabNet] time_cost : 0.02596569061279297\n",
      "[2021-02-03 13:58:38,431][INFO][TabNet] mean_squared_error : 2.9847896099090576\n",
      "[2021-02-03 13:58:38,433][INFO][TabNet] ******************** epoch : 136 ********************\n",
      "[2021-02-03 13:58:42,123][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:42,126][INFO][TabNet] total_loss : 15.76925277709961\n",
      "[2021-02-03 13:58:42,129][INFO][TabNet] task_loss : 15.768997192382812\n",
      "[2021-02-03 13:58:42,131][INFO][TabNet] mask_loss : -0.25553566217422485\n",
      "[2021-02-03 13:58:42,134][INFO][TabNet] time_cost : 0.017998456954956055\n",
      "[2021-02-03 13:58:42,136][INFO][TabNet] mean_squared_error : 2.9038643836975098\n",
      "[2021-02-03 13:58:42,138][INFO][TabNet] ******************** epoch : 137 ********************\n",
      "[2021-02-03 13:58:45,949][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:45,951][INFO][TabNet] total_loss : 11.310482025146484\n",
      "[2021-02-03 13:58:45,953][INFO][TabNet] task_loss : 11.31021499633789\n",
      "[2021-02-03 13:58:45,955][INFO][TabNet] mask_loss : -0.26677206158638\n",
      "[2021-02-03 13:58:45,956][INFO][TabNet] time_cost : 0.02999711036682129\n",
      "[2021-02-03 13:58:45,957][INFO][TabNet] mean_squared_error : 2.563483953475952\n",
      "[2021-02-03 13:58:45,959][INFO][TabNet] ******************** epoch : 138 ********************\n",
      "[2021-02-03 13:58:50,200][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:50,202][INFO][TabNet] total_loss : 12.561904907226562\n",
      "[2021-02-03 13:58:50,204][INFO][TabNet] task_loss : 12.561644554138184\n",
      "[2021-02-03 13:58:50,205][INFO][TabNet] mask_loss : -0.2607996165752411\n",
      "[2021-02-03 13:58:50,207][INFO][TabNet] time_cost : 0.024972200393676758\n",
      "[2021-02-03 13:58:50,208][INFO][TabNet] mean_squared_error : 2.5856990814208984\n",
      "[2021-02-03 13:58:50,210][INFO][TabNet] ******************** epoch : 139 ********************\n",
      "[2021-02-03 13:58:53,945][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:53,948][INFO][TabNet] total_loss : 14.32053279876709\n",
      "[2021-02-03 13:58:53,951][INFO][TabNet] task_loss : 14.32027530670166\n",
      "[2021-02-03 13:58:53,953][INFO][TabNet] mask_loss : -0.2574644982814789\n",
      "[2021-02-03 13:58:53,955][INFO][TabNet] time_cost : 0.024999618530273438\n",
      "[2021-02-03 13:58:53,957][INFO][TabNet] mean_squared_error : 2.779160499572754\n",
      "[2021-02-03 13:58:53,959][INFO][TabNet] ******************** epoch : 140 ********************\n",
      "[2021-02-03 13:58:57,755][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:58:57,757][INFO][TabNet] total_loss : 11.902091979980469\n",
      "[2021-02-03 13:58:57,760][INFO][TabNet] task_loss : 11.901832580566406\n",
      "[2021-02-03 13:58:57,761][INFO][TabNet] mask_loss : -0.2590794861316681\n",
      "[2021-02-03 13:58:57,763][INFO][TabNet] time_cost : 0.023993968963623047\n",
      "[2021-02-03 13:58:57,765][INFO][TabNet] mean_squared_error : 2.504565715789795\n",
      "[2021-02-03 13:58:57,766][INFO][TabNet] ******************** epoch : 141 ********************\n",
      "[2021-02-03 13:59:01,625][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:59:01,629][INFO][TabNet] total_loss : 18.611087799072266\n",
      "[2021-02-03 13:59:01,632][INFO][TabNet] task_loss : 18.61082649230957\n",
      "[2021-02-03 13:59:01,634][INFO][TabNet] mask_loss : -0.2609309256076813\n",
      "[2021-02-03 13:59:01,637][INFO][TabNet] time_cost : 0.016998291015625\n",
      "[2021-02-03 13:59:01,639][INFO][TabNet] mean_squared_error : 3.1376352310180664\n",
      "[2021-02-03 13:59:01,641][INFO][TabNet] ******************** epoch : 142 ********************\n",
      "[2021-02-03 13:59:05,337][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:59:05,339][INFO][TabNet] total_loss : 10.788658142089844\n",
      "[2021-02-03 13:59:05,341][INFO][TabNet] task_loss : 10.788395881652832\n",
      "[2021-02-03 13:59:05,344][INFO][TabNet] mask_loss : -0.262543648481369\n",
      "[2021-02-03 13:59:05,345][INFO][TabNet] time_cost : 0.022000789642333984\n",
      "[2021-02-03 13:59:05,347][INFO][TabNet] mean_squared_error : 2.56357479095459\n",
      "[2021-02-03 13:59:05,349][INFO][TabNet] ******************** epoch : 143 ********************\n",
      "[2021-02-03 13:59:09,035][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:59:09,038][INFO][TabNet] total_loss : 15.609334945678711\n",
      "[2021-02-03 13:59:09,041][INFO][TabNet] task_loss : 15.609066009521484\n",
      "[2021-02-03 13:59:09,042][INFO][TabNet] mask_loss : -0.2692504823207855\n",
      "[2021-02-03 13:59:09,044][INFO][TabNet] time_cost : 0.021950721740722656\n",
      "[2021-02-03 13:59:09,045][INFO][TabNet] mean_squared_error : 2.815751791000366\n",
      "[2021-02-03 13:59:09,046][INFO][TabNet] ******************** epoch : 144 ********************\n",
      "[2021-02-03 13:59:12,983][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:59:12,985][INFO][TabNet] total_loss : 15.591392517089844\n",
      "[2021-02-03 13:59:12,988][INFO][TabNet] task_loss : 15.591144561767578\n",
      "[2021-02-03 13:59:12,990][INFO][TabNet] mask_loss : -0.2483087033033371\n",
      "[2021-02-03 13:59:12,991][INFO][TabNet] time_cost : 0.023000717163085938\n",
      "[2021-02-03 13:59:12,993][INFO][TabNet] mean_squared_error : 2.960880756378174\n",
      "[2021-02-03 13:59:12,994][INFO][TabNet] ******************** epoch : 145 ********************\n",
      "[2021-02-03 13:59:16,905][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:59:16,907][INFO][TabNet] total_loss : 13.676104545593262\n",
      "[2021-02-03 13:59:16,909][INFO][TabNet] task_loss : 13.675844192504883\n",
      "[2021-02-03 13:59:16,912][INFO][TabNet] mask_loss : -0.259983628988266\n",
      "[2021-02-03 13:59:16,914][INFO][TabNet] time_cost : 0.01800060272216797\n",
      "[2021-02-03 13:59:16,915][INFO][TabNet] mean_squared_error : 2.6638906002044678\n",
      "[2021-02-03 13:59:16,917][INFO][TabNet] ******************** epoch : 146 ********************\n",
      "[2021-02-03 13:59:20,713][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:59:20,715][INFO][TabNet] total_loss : 14.091022491455078\n",
      "[2021-02-03 13:59:20,717][INFO][TabNet] task_loss : 14.090746879577637\n",
      "[2021-02-03 13:59:20,718][INFO][TabNet] mask_loss : -0.27605849504470825\n",
      "[2021-02-03 13:59:20,720][INFO][TabNet] time_cost : 0.02799677848815918\n",
      "[2021-02-03 13:59:20,722][INFO][TabNet] mean_squared_error : 2.6497645378112793\n",
      "[2021-02-03 13:59:20,723][INFO][TabNet] ******************** epoch : 147 ********************\n",
      "[2021-02-03 13:59:24,592][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:59:24,594][INFO][TabNet] total_loss : 11.708721160888672\n",
      "[2021-02-03 13:59:24,596][INFO][TabNet] task_loss : 11.708459854125977\n",
      "[2021-02-03 13:59:24,598][INFO][TabNet] mask_loss : -0.2613097131252289\n",
      "[2021-02-03 13:59:24,599][INFO][TabNet] time_cost : 0.021997451782226562\n",
      "[2021-02-03 13:59:24,601][INFO][TabNet] mean_squared_error : 2.773160219192505\n",
      "[2021-02-03 13:59:24,602][INFO][TabNet] ******************** epoch : 148 ********************\n",
      "[2021-02-03 13:59:28,530][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:59:28,532][INFO][TabNet] total_loss : 16.286052703857422\n",
      "[2021-02-03 13:59:28,533][INFO][TabNet] task_loss : 16.285789489746094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-03 13:59:28,535][INFO][TabNet] mask_loss : -0.2629603445529938\n",
      "[2021-02-03 13:59:28,537][INFO][TabNet] time_cost : 0.029003143310546875\n",
      "[2021-02-03 13:59:28,538][INFO][TabNet] mean_squared_error : 2.769136905670166\n",
      "[2021-02-03 13:59:28,540][INFO][TabNet] ******************** epoch : 149 ********************\n",
      "[2021-02-03 13:59:32,611][INFO][TabNet] -------------------- train info --------------------\n",
      "[2021-02-03 13:59:32,613][INFO][TabNet] total_loss : 15.585423469543457\n",
      "[2021-02-03 13:59:32,615][INFO][TabNet] task_loss : 15.58518123626709\n",
      "[2021-02-03 13:59:32,617][INFO][TabNet] mask_loss : -0.24261583387851715\n",
      "[2021-02-03 13:59:32,621][INFO][TabNet] time_cost : 0.023003816604614258\n",
      "[2021-02-03 13:59:32,622][INFO][TabNet] mean_squared_error : 2.848806142807007\n",
      "[2021-02-03 13:59:32,624][INFO][TabNet] ******************** epoch : 150 ********************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f40a9c2ad15d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtabnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\yiliu\\TabNet_Pytorch\\tabnet\\estimator\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, feats, targets, batch_size, max_epochs, optimizer, optimizer_params, schedulers, scheduler_params, metrics, valid_feats, valid_targets, valid_metrics)\u001b[0m\n\u001b[0;32m    349\u001b[0m             train_meter = train_epoch(\n\u001b[0;32m    350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_processor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_criterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m             )\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\yiliu\\TabNet_Pytorch\\tabnet\\core\\_solver.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, epoch, post_processor, criterion, optimizer, metrics, logger, device)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         show_message(\n\u001b[0;32m     76\u001b[0m             \u001b[1;34m'[Train] ==================== batch : {} ===================='\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\demucs\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\demucs\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\demucs\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\demucs\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\demucs\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\demucs\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\demucs\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tabnet.fit(X, y.reshape(-1, 1), **training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance, masks = tabnet.explain(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 1, figsize=(5,15))\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i].cpu().numpy()[:20])\n",
    "#     axs[i].set_xlabel('features')\n",
    "    axs[i].set_ylabel('samples')\n",
    "    axs[i].set_title(f\"mask {i}\")\n",
    "    axs[i].set_yticks(range(20))\n",
    "#     axs[i].set_xticks(range(30))\n",
    "#     axs[i].set_xticklabels(feature_names, rotation=90)\n",
    "\n",
    "axs[3].imshow(importance.cpu().numpy()[:20, :])\n",
    "axs[3].set_xlabel('features')\n",
    "axs[3].set_ylabel('samples')\n",
    "axs[3].set_title('importance')\n",
    "axs[3].set_yticks(range(20))\n",
    "axs[3].set_xticks(range(13))\n",
    "axs[3].set_xticklabels(feature_names, rotation=90)\n",
    "plt.show()\n",
    "axs[3].set_title('importance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
